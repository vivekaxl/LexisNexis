from __future__ import division
import sys,collections,random

from functools import partial
from itertools import product
from models import *
from witschey.models import Model
from witschey.models import IndependentVariable as IV
from witschey.searchers import  DifferentialEvolution, ParticleSwarmOptimizer

class KNNModel(Model):

    def __init__(self, train, test, most):
        # the order of the independents and the cart_wrapper are coupled
        # and that's gross

        self.train, self.test, self.most = train, test, most

        independents = (
          IV(lo=1, hi=len(self.train), name='n_neighbors', gen_type=int),
          IV(valid_inputs=('euclidean', 'manhattan',
                           'chebyshev', 'minkowski',
                           # 'mahalanobis' 2d array only
                           ), name='metric'),
          IV(valid_inputs=('ball_tree', 'kd_tree', 'brute'),
                           name='algorithm'),
          # IV(valid_inputs=('uniform', 'distance'), name='weights'),
          IV(lo=1, hi=100, name='leaf_size', gen_type=int))

        super(KNNModel, self).__init__(
            independents=independents, dependents=(self.knn_wrapper,))

    # the order of the independets and this function parameters are
    # coupled
    # and that's gross
    def knn_wrapper(self, xs):
        from sklearn.neighbors import KNeighborsRegressor
        # n_neighbors, metric, algorithm, weights, leaf_size = xs
        n_neighbors, metric, algorithm, leaf_size = xs
        indep = map(lambda x: x[:self.most+1], self.train)
        dep   = map(lambda x: x[self.most+1],  self.train)
        r = KNeighborsRegressor(
          n_neighbors=n_neighbors,
          metric=metric,
          algorithm=algorithm,
          # weights=weights,
          leaf_size=leaf_size
          ).fit(indep,dep)
        return r.predict(self.test[:self.most+1])[0]

def run_de_knn(train, test, most, **kw):
  s = DifferentialEvolution(partial(KNNModel, train, test, most))
  result = s.run()
  return result.best


class CARTModel(Model):

    def __init__(self, train, test, most):
        # the order of the independents and the cart_wrapper are coupled
        # and that's gross

        self.train, self.test, self.most = train, test, most

        independents = (IV(lo=1, hi=100, name='min_samples_split', gen_type=int),
                        IV(lo=2, hi=200, name='max_leaf_nodes', gen_type=int))
          # IV(valid_inputs=('best', 'random'), name='splitter'),

        super(CARTModel, self).__init__(
            independents=independents, dependents=(self.cart_wrapper,))

    # the order of the independets and this function parameters are
    # coupled
    # and that's gross
    def cart_wrapper(self, xs):
        min_samples_split, max_leaf_nodes = xs
        # splitter, min_samples_split, max_leaf_nodes = xs

        # for x, arg in zip(self.xs, (splitter, min_samples_split, max_leaf_nodes)):
        for x, arg in zip(self.xs, (min_samples_split, max_leaf_nodes)):
            if not x.valid(arg):
                raise ModelInputException()

        return cart(self.train, self.test, self.most,
                    # splitter=splitter,
                    min_samples_split=min_samples_split,
                    max_leaf_nodes=max_leaf_nodes)

class RFModel(Model):

    def __init__(self, train, test, most):
        # the order of the independents and the cart_wrapper are coupled
        # and that's gross

        self.train, self.test, self.most = train, test, most

        independents = (IV(lo=1, hi=100, name='min_samples_split', gen_type=int),
                        IV(lo=2, hi=200, name='max_leaf_nodes', gen_type=int))

        super(RFModel, self).__init__(
            independents=independents, dependents=(self.forest_wrapper,))

    # the order of the independets and this function parameters are
    # coupled
    # and that's gross
    def forest_wrapper(self, xs):
        min_samples_split, max_leaf_nodes = xs

        return forest(self.train, self.test, self.most,
                      min_samples_split=min_samples_split,
                      max_leaf_nodes=max_leaf_nodes,
                      n_estimators=150)


class VerboseCARTModel(Model):

    def __init__(self, n, train, test, most):
        # the order of the independents and the cart_wrapper are coupled
        # and that's gross

        self.train, self.test, self.most = train, test, most

        independents = (IV(lo=1, hi=24, name='min_samples_split', gen_type=int),
                        IV(lo=2, hi=24, name='max_leaf_nodes', gen_type=int))

        super(VerboseCARTModel, self).__init__(
            independents=independents, dependents=(self.cart_wrapper,))

    # the order of the independets and this function parameters are
    # coupled
    # and that's gross
    def cart_wrapper(self, xs):
        min_samples_split, max_leaf_nodes = xs

        return verbose_cart(self.train, self.test, self.most,
                            min_samples_split=min_samples_split,
                            max_leaf_nodes=max_leaf_nodes)


def show_params(f):
  from functools import wraps

  @wraps(f)
  def wrapped(*args, **kwargs):
    # print args, kwargs
    return f(*args, **kwargs)

  return wrapped


def shuffle(lst):
  random.shuffle(lst)
  return lst

class Thing():
  id = -1
  def __init__(i,**fields) : 
    i.override(fields)
    i._id = Thing.id = Thing.id + 1
    i.finalize()
  def finalize(i): pass
  def override(i,d): i.__dict__.update(d); return i
  def plus(i,**d): i.override(d)
  def __repr__(i):
    d = i.__dict__
    name = i.__class__.__name__
    return name+'{'+' '.join([':%s %s' % (k,pretty(d[k])) 
                     for k in i.show()])+ '}'
  def show(i):
    return [k for k in sorted(i.__dict__.keys()) 
            if not k.startswith('_')]

def tunings( _ = None):
  return dict( 
    Flex= [5.07, 4.05, 3.04, 2.03, 1.01,    _],
    Pmat= [7.80, 6.24, 4.68, 3.12, 1.56,    _],
    Prec= [6.20, 4.96, 3.72, 2.48, 1.24,    _],
    Resl= [7.07, 5.65, 4.24, 2.83, 1.41,    _],
    Team= [5.48, 4.38, 3.29, 2.19, 1.01,    _], 
    acap= [1.42, 1.19, 1.00, 0.85, 0.71,    _], 
    aexp= [1.22, 1.10, 1.00, 0.88, 0.81,    _], 
    cplx= [0.73, 0.87, 1.00, 1.17, 1.34, 1.74], 
    data= [   _, 0.90, 1.00, 1.14, 1.28,    _], 
    docu= [0.81, 0.91, 1.00, 1.11, 1.23,    _],
    ltex= [1.20, 1.09, 1.00, 0.91, 0.84,    _], 
    pcap= [1.34, 1.15, 1.00, 0.88, 0.76,    _], 
    pcon= [1.29, 1.12, 1.00, 0.90, 0.81,    _], 
    plex= [1.19, 1.09, 1.00, 0.91, 0.85,    _], 
    pvol= [   _, 0.87, 1.00, 1.15, 1.30,    _], 
    rely= [0.82, 0.92, 1.00, 1.10, 1.26,    _], 
    ruse= [   _, 0.95, 1.00, 1.07, 1.15, 1.24], 
    sced= [1.43, 1.14, 1.00, 1.00, 1.00,    _], 
    site= [1.22, 1.09, 1.00, 0.93, 0.86, 0.80], 
    stor= [   _,    _, 1.00, 1.05, 1.17, 1.46], 
    time= [   _,    _, 1.00, 1.11, 1.29, 1.63], 
    tool= [1.17, 1.09, 1.00, 0.90, 0.78,    _])



Features=dict(Sf=[ 'Prec','Flex','Resl','Team','Pmat'],
              Prod=['rely','data','cplx','ruse','docu'],
              Platform=['time','stor','pvol'],
              Person=['acap','pcap','pcon','aexp','plex','ltex'],
              Project=['tool','site','sced'])

def options():
  return Thing(levels=10,samples=20,shrink=0.66,round=2,epsilon=0.00,
               guesses=1000)


Features=dict(Sf=[ 'Prec','Flex','Resl','Team','Pmat'],
              Prod=['rely','data','cplx','ruse','docu'],
              Platform=['time','stor','pvol'],
              Person=['acap','pcap','pcon','aexp','plex','ltex'],
              Project=['tool','site','sced'])

def has(x,lst):
 try:
   out=lst.index(x)
   return out
 except ValueError:
    return None

def china(opt=options(),tunings=tunings()):
  vl=1;l=2;n=3;h=4;vh=5;xh=6;_=0
  return Thing(
    sfem=15,
    kloc=16,
    effort=17,
    names =[
     'AFP','Input','Output','Enquiry','File','Interface','Added','Changed','Deleted',
     'PDR_AFP', 'PDR_UFP', 'NPDR_AFP', 'NPDU_UFP', 'Resource', 'Dev.Type', 'Duration',
    'effort','n_effort'],
    projects=[
     [1587,774,260,340,128,0,1502,0,0,4.7,5,4.7,5,4,0,4,7490,7490],
      [260,9,4,3,193,41,51,138,61,16,16.6,16,16.6,2,0,17,4150,4150],
      [152,25,33,28,42,35,163,0,0,4.4,4.1,4.4,4.1,1,0,9,668,668],
      [252,151,28,8,39,0,69,153,4,12.8,14.3,15.5,17.3,1,0,4,3238,3901],
      [292,93,0,194,20,0,0,307,0,10.3,9.8,12.4,11.7,1,0,13,2994,3607],
      [83,63,0,24,0,0,0,87,0,16.1,15.3,19.3,18.5,1,0,4,1333,1606],
      [79,24,0,23,30,0,0,77,0,20.3,20.9,24.5,25.1,1,0,6,1607,1936],
      [97,0,108,7,0,5,120,0,0,11.9,9.7,11.9,9.7,2,0,7,1158,1158],
      [116,0,23,58,14,20,81,34,0,10.7,10.8,12.9,13,1,0,6,1243,1498],
      [52,39,7,0,0,0,0,46,0,64.8,73.3,78.1,88.3,1,0,7,3372,4063],
      [465,209,129,24,83,15,460,0,0,21.9,22.2,21.9,22.2,1,0,9,10200,10200],
      [67,32,5,16,7,0,25,35,0,25.4,28.4,30.6,34.2,1,0,7,1704,2053],
      [199,0,115,57,0,42,214,0,0,13.3,12.3,15.2,14.2,2,0,7,2640,3034],
      [176,13,54,54,40,7,168,0,0,19,19.9,19,19.9,1,0,26,3348,3348],
      [391,208,26,81,25,0,38,302,0,1.7,2,2.1,2.4,1,0,7,676,814],
      [263,65,45,101,42,10,176,87,0,3.5,3.5,3.5,3.5,1,0,3,911,911],
      [42,12,15,3,7,15,52,0,0,59.4,48,59.4,48,1,0,6.4,2496,2496],
      [190,98,20,16,63,5,160,42,0,6.2,5.8,6.2,5.8,1,0,10,1171,1171],
      [245,105,28,18,58,0,19,190,0,14.4,16.9,14.4,16.9,1,0,13,3532,3532],
      [77,28,0,42,0,0,0,70,0,5.7,6.2,6.8,7.5,1,0,1,436,525],
      [355,278,0,73,0,0,0,351,0,2.6,2.6,3.1,3.1,1,0,4,909,1095],
      [3156,2075,525,97,0,0,28,12,2657,2.9,3.4,3.5,4.1,1,0,6,9094,10957],
      [46,0,28,0,25,0,28,25,0,7.5,6.5,7.5,6.5,1,0,6,344,344],
      [56,14,12,15,7,5,53,0,0,5.3,5.6,5.3,5.6,4,0,3,296,296],
      [106,65,4,12,14,0,35,53,7,33,36.9,39.8,44.4,1,0,13,3503,4220],
      [71,31,28,9,7,0,31,23,21,3.5,3.3,4.2,3.9,1,0,1,246,296],
      [306,51,105,0,105,45,306,0,0,6.8,6.8,6.8,6.8,2,0,24,2082,2082],
      [244,68,78,22,62,14,244,0,0,0.8,0.8,0.8,0.8,4,0,7,191,191],
      [98,21,46,3,44,0,114,0,0,30.3,26.1,36.6,31.4,1,0,15,2974,3583],
      [331,100,44,61,107,0,312,0,0,1,1.1,1.2,1.3,1,0,2,328,395],
      [101,16,5,39,52,0,112,0,0,4,3.6,4,3.6,1,0,8,406,406],
      [192,9,102,0,10,77,198,0,0,9.3,9,11.2,10.9,1,0,8,1785,2151],
      [60,39,4,0,14,10,39,22,6,7.9,7,7.9,7,2,0,8,471,471],
      [180,74,18,33,57,0,153,29,0,3.9,3.8,3.9,3.8,2,0,5,700,700],
      [118,43,71,7,0,0,38,83,0,4.9,4.8,5.9,5.8,1,0,2,579,698],
      [73,43,10,4,15,0,6,66,0,16.6,16.8,20,20.3,1,0,3,1211,1459],
      [143,63,0,27,45,0,14,121,0,8,8.4,9.6,10.2,1,0,4,1139,1372],
      [2190,706,648,236,235,0,1825,0,0,6.6,8,7.6,9.1,2,0,19,14520,16690],
      [9,0,10,0,0,0,5,5,0,26.6,23.9,26.6,23.9,1,0,2,239,239],
      [203,21,167,3,10,0,201,0,0,6.2,6.3,7.5,7.6,1,0,5,1262,1520],
      [162,64,36,9,28,20,157,0,0,10.8,11.2,10.8,11.2,1,0,8,1754,1754],
      [183,60,21,29,71,0,181,0,0,8.3,8.4,10,10.1,1,0,6,1514,1824],
      [59,36,21,0,0,0,6,51,0,11.3,11.7,13.6,14.1,1,0,8,667,804],
      [412,198,14,99,91,10,412,0,0,14.2,14.2,14.2,14.2,1,0,20,5864,5864],
      [348,198,14,33,77,0,10,312,0,2.8,3,3.4,3.6,1,0,3,973,1172],
      [2529,554,513,66,703,220,2056,0,0,2.1,2.6,2.1,2.6,2,0,13,5333,5333],
      [250,28,92,57,0,30,164,43,0,7.1,8.6,7.1,8.6,2,0,8,1775,1775],
      [206,0,199,0,0,5,100,104,0,1,1,1.2,1.2,1,0,5,204,246],
      [617,184,136,103,133,0,377,179,0,5.1,5.7,6.1,6.8,1,0,7,3148,3793],
      [173,0,78,10,17,72,177,0,0,50.4,49.2,60.7,59.3,1,0,12,8716,10501],
      [286,45,156,27,37,0,265,0,0,5.1,5.5,5.1,5.5,1,0,6,1464,1464],
      [52,13,17,6,10,5,20,16,15,26.1,26.6,31.5,32.1,1,0,2,1358,1636],
      [45,6,28,0,0,25,59,0,0,6.2,4.8,6.2,4.8,2,0,7,281,281],
      [104,30,7,48,15,0,0,100,0,22.3,23.2,26.9,28,1,0,5,2321,2796],
      [465,234,44,104,118,0,431,15,54,8.7,8.1,10.5,9.8,1,0,13,4054,4884],
      [2145,862,63,491,518,300,2234,0,0,1.1,1.1,1.1,1.1,4,0,84,2400,2400],
      [283,20,125,39,91,17,292,0,0,20,19.3,20,19.3,1,0,13,5650,5650],
      [109,0,84,0,17,5,47,59,0,14,14.4,16.9,17.3,1,0,2,1525,1837],
      [160,0,21,72,25,40,74,68,16,3,3,3.6,3.6,1,0,2,477,575],
      [65,0,64,0,0,0,54,10,0,7.7,7.9,9.3,9.5,1,0,2,503,606],
      [366,160,27,96,72,0,260,84,11,23.1,23.9,27.9,28.7,1,0,10,8470,10205],
      [63,18,10,3,28,0,16,43,0,12.3,13.2,14.9,15.9,1,0,3,778,937],
      [309,126,13,59,153,30,381,0,0,8.4,6.8,8.4,6.8,4,0,7.5,2597,2597],
      [610,137,174,117,147,0,575,0,0,1.6,1.7,1.6,1.7,1,0,3,950,950],
      [562,165,125,93,119,0,502,0,0,10.2,11.4,10.2,11.4,3,0,13,5727,5727],
      [156,21,38,39,7,41,146,0,0,13.1,14,15.8,16.8,1,0,4,2040,2458],
      [75,30,5,19,21,0,40,35,0,49,49,59.1,59.1,1,0,8,3677,4430],
      [136,42,64,0,21,0,0,127,0,4.2,4.5,5.1,5.4,1,0,2,570,687],
      [96,13,56,0,10,40,119,0,0,12.7,10.3,47.2,38.1,2,0,8,1223,4530],
      [78,24,24,9,21,0,78,0,0,12.5,12.5,13.9,13.9,1,0,4,976,1084],
      [51,42,0,14,0,0,20,36,0,7.6,6.9,9.1,8.3,1,0,12,387,466],
      [1092,356,84,170,669,21,1300,0,0,4,3.4,4.9,4.1,1,0,13,4416,5320],
      [134,42,11,32,35,14,134,0,0,2.1,2.1,2.6,2.6,1,0,8,286,345],
      [75,24,9,0,36,0,0,69,0,4.1,4.4,4.9,5.3,1,0,5,305,367],
      [88,18,20,0,43,0,36,45,0,1.5,1.6,1.8,1.9,1,0,7,129,155],
      [3088,1061,1009,772,241,5,544,2544,0,1.4,1.4,1.4,1.4,1,0,8,4266,4266],
      [82,25,46,0,14,15,100,0,0,5.4,4.4,5.4,4.4,1,0,3,440,440],
      [110,30,66,0,7,0,18,85,0,12.4,13.2,12.4,13.2,1,0,2,1362,1362],
      [308,153,83,0,112,10,236,122,0,8.2,7.1,8.2,7.1,2,0,6,2533,2533],
      [143,75,32,3,62,0,172,0,0,1.6,1.3,1.6,1.3,1,0,10,225,225],
      [826,292,326,155,32,0,396,139,270,13.4,13.7,13.4,13.7,1,0,13,11045,11045],
      [3460,484,1831,318,208,142,2756,227,0,9.5,11,9.5,11,4,0,24,32760,32760],
      [73,15,32,0,28,5,80,0,0,28.1,25.7,33.9,30.9,1,0,8,2054,2475],
      [64,4,56,0,7,0,11,56,0,3.9,3.8,3.9,3.8,1,0,7,252,252],
      [497,122,28,113,273,10,454,92,0,4.8,4.3,4.8,4.3,2,0,8,2362,2362],
      [288,201,0,36,76,0,99,214,0,8.5,7.9,10.3,9.5,1,0,5,2459,2963],
      [494,134,62,140,91,67,494,0,0,17.6,17.6,17.6,17.6,1,0,21,8706,8706],
      [130,60,65,0,0,0,14,111,0,5.9,6.2,5.9,6.2,1,0,6,770,770],
      [204,47,43,6,29,104,229,0,0,39.8,35.4,39.8,35.4,1,0,36,8111,8111],
      [17,12,5,0,0,0,17,0,0,44.8,44.8,44.8,44.8,1,0,11,762,762],
      [60,10,25,0,31,5,71,0,0,2.3,1.9,2.7,2.3,1,0,1,136,164],
      [73,0,20,36,10,0,56,10,0,4.9,5.4,5.9,6.5,1,0,1,358,431],
      [169,32,14,25,28,70,169,0,0,2.8,2.8,3.4,3.4,1,0,6,481,580],
      [1351,379,449,271,219,20,1173,29,136,2.4,2.4,2.8,2.9,1,0,8,3189,3842],
      [2087,862,444,303,437,0,2046,0,0,10.8,11,10.8,11,4,0,9,22500,22500],
      [253,72,0,107,29,44,252,0,0,46.3,46.3,49.8,49.8,1,0,13,11719,12601],
      [102,37,26,10,29,0,102,0,0,1.8,1.8,2.4,2.4,1,0,5,183,244],
      [115,49,39,0,15,0,53,50,0,12.9,14.4,15.5,17.3,1,0,5,1482,1786],
      [288,18,186,21,15,60,300,0,0,4.3,4.2,4.3,4.2,2,0,11,1251,1251],
      [199,104,7,77,0,0,0,188,0,4.7,5,5.7,6,1,0,8,943,1136],
      [163,49,14,33,49,10,155,0,0,16.5,17.3,19.8,20.9,1,0,11,2684,3234],
      [97,21,41,0,49,15,16,100,10,7.5,5.8,7.5,5.8,2,0,9,729,729],
      [439,82,222,19,85,10,105,313,0,8.3,8.7,8.3,8.7,1,0,7,3630,3630],
      [3113,2019,609,248,157,80,3113,0,0,10.9,10.9,13.5,13.5,1,0,24,34085,42080],
      [153,35,7,57,24,20,143,0,0,18.7,20,21.5,23,2,0,3,2856,3283],
      [670,346,97,122,79,0,146,498,0,8.6,8.9,10.4,10.8,1,0,6,5757,6936],
      [129,19,93,3,10,30,0,155,0,4.9,4.1,4.9,4.1,2,0,15,631,631],
      [329,324,68,14,0,0,206,73,127,6.6,5.4,6.6,5.4,2,0,8,2184,2184],
      [5684,2221,454,820,1137,311,4943,0,0,3.7,4.3,3.7,4.3,1,0,37,21014,21014],
      [61,27,4,24,17,0,72,0,0,6.8,5.8,8.2,7,1,0,4,417,502],
      [267,27,133,51,34,89,70,178,86,10,8,10,8,2,0,9,2683,2683],
      [218,78,16,56,77,0,227,0,0,25.4,24.4,30.6,29.4,1,0,4,5532,6665],
      [919,458,236,56,58,76,884,0,0,5.2,5.4,6.3,6.6,1,0,6,4815,5801],
      [66,27,12,6,14,0,28,31,0,3.7,4.2,4.5,5,1,0,2,246,296],
      [54,36,0,16,0,0,0,52,0,12.7,13.2,15.3,15.9,1,0,1,686,827],
      [245,88,105,27,79,0,299,0,0,1.9,1.6,3.6,2.9,1,0,13,470,870],
      [54,24,28,0,0,0,0,52,0,7.3,7.6,8.8,9.2,1,0,2,395,476],
      [151,40,54,15,21,0,111,19,0,7.2,8.3,8.2,9.5,2,0,3,1080,1241],
      [103,45,4,27,29,0,105,0,0,13.6,13.3,13.6,13.3,2,0,7,1396,1396],
      [300,95,82,27,76,0,138,142,0,9.8,10.5,9.8,10.5,1,0,10,2933,2933],
      [249,126,4,98,21,0,58,191,0,18.3,18.3,18.3,18.3,1,0,9,4551,4551],
      [224,156,21,0,29,10,6,210,0,13.4,13.9,16.1,16.7,1,0,4,2999,3613],
      [1984,255,1008,192,158,0,1613,0,0,1.3,1.6,1.3,1.6,2,0,11,2540,2540],
      [58,15,37,0,0,5,0,57,0,0.4,0.5,0.5,0.5,1,0,2,26,31],
      [56,50,0,3,0,0,0,53,0,8,8.5,9.6,10.2,1,0,2,448,540],
      [244,91,12,44,60,50,257,0,0,3.7,3.5,4.5,4.2,1,0,3,906,1092],
      [12,0,0,6,7,0,10,3,0,17.6,16.2,17.6,16.2,2,0,13,211,211],
      [1416,402,432,0,252,65,376,775,0,1.2,1.5,1.2,1.5,2,0,12,1724,1724],
      [67,3,26,0,7,35,71,0,0,23.6,22.3,27.2,25.6,2,0,5,1584,1821],
      [95,36,0,32,24,0,0,92,0,1.6,1.6,1.9,1.9,1,0,7,148,178],
      [2376,638,233,639,580,131,2221,0,0,10.7,11.5,12.9,13.8,1,0,24,25482,30701],
      [442,225,102,57,91,0,82,393,0,1.5,1.4,1.5,1.4,1,0,5,683,683],
      [68,21,12,19,15,0,11,56,0,37.1,37.6,44.7,45.3,1,0,4,2521,3037],
      [268,76,96,45,41,10,248,20,0,10.9,10.9,10.9,10.9,2,0,9,2933,2933],
      [90,96,0,0,0,0,96,0,0,5.5,5.1,6.6,6.2,1,0,2,494,595],
      [72,23,25,7,17,0,55,17,0,6.8,6.8,6.8,6.8,1,0,7,486,486],
      [505,111,127,18,216,0,472,0,0,9.8,10.5,9.8,10.5,1,0,30,4955,4955],
      [450,112,145,59,105,0,356,58,7,13.6,14.6,13.6,14.6,1,0,7,6138,6138],
      [230,129,38,46,57,0,230,40,0,6.3,5.4,7.6,6.5,1,0,10,1451,1748],
      [242,97,78,4,43,0,0,222,0,1.3,1.4,1.5,1.7,1,0,2,311,375],
      [106,21,76,6,0,0,7,96,0,23.1,23.7,27.8,28.6,1,0,2,2445,2946],
      [31,10,14,0,7,0,4,27,0,7.6,7.6,7.6,7.6,1,0,6,237,237],
      [1186,422,306,109,168,230,1235,0,0,3.1,3,3.1,3,3,0,9,3711,3711],
      [256,69,198,0,0,5,272,0,0,11.5,10.8,11.5,10.8,2,0,19,2941,2941],
      [191,44,60,15,49,25,159,34,0,12.7,12.6,12.7,12.6,2,0,11,2430,2430],
      [213,102,63,6,28,0,186,13,0,11.9,12.7,14.3,15.3,1,0,10,2532,3051],
      [4562,1098,1278,498,1059,0,3933,0,0,5.8,6.7,5.8,6.7,1,0,15,26408,26408],
      [141,44,33,44,17,0,5,133,0,8.8,9,10.6,10.9,1,0,2,1244,1499],
      [187,23,65,17,91,5,201,0,0,3,2.8,3.6,3.4,1,0,6,562,677],
      [128,45,0,68,0,15,128,0,0,25.8,25.8,56.1,56.1,1,0,10,3303,7180],
      [194,70,16,0,45,47,46,132,0,2.6,2.8,3.6,3.9,1,0,12,499,703],
      [869,288,300,116,230,0,934,0,0,2.4,2.2,2.4,2.2,3,0,6,2078,2078],
      [125,51,9,33,22,0,20,84,11,18.6,20.2,22.4,24.4,1,0,3,2326,2802],
      [477,235,117,89,46,10,172,218,107,5.7,5.5,5.7,5.5,1,0,6,2741,2741],
      [717,716,13,10,24,0,51,712,0,4.9,4.6,6,5.6,1,0,5,3546,4272],
      [25,0,28,0,0,0,0,28,0,5.6,5,5.6,5,1,0,3,140,140],
      [73,9,61,3,0,0,73,0,0,19.2,19.2,19.2,19.2,1,0,8,1404,1404],
      [100,61,0,0,0,42,28,75,0,9.3,9,11.2,10.9,1,0,12,929,1119],
      [273,103,183,15,17,0,318,0,0,1.9,1.7,1.9,1.7,3,0,5,528,528],
      [587,108,119,94,203,0,524,0,0,6.4,7.2,6.4,7.2,3,0,15,3748,3748],
      [1437,920,154,41,203,0,1318,0,0,3.4,3.7,3.4,3.7,4,0,18,4900,4900],
      [97,3,101,3,0,7,108,6,0,19.1,16.3,19.1,16.3,2,0,12,1853,1853],
      [224,110,25,6,49,5,195,0,0,12.9,14.8,14.8,17,2,0,13,2890,3322],
      [321,168,46,9,77,15,315,0,0,3.4,3.4,3.4,3.4,4,0,11,1076,1076],
      [99,6,4,19,59,10,98,0,0,24.1,24.4,29.1,29.3,1,0,4,2387,2876],
      [416,179,40,54,109,7,318,65,6,3.8,4.1,4.6,4.9,1,0,6,1586,1911],
      [71,21,21,4,14,5,25,40,0,14,15.3,16.9,18.5,1,0,4,997,1201],
      [120,60,48,12,0,0,12,108,0,1.8,1.8,1.8,1.8,1,0,5,212,212],
      [213,72,43,3,84,30,132,97,3,6,5.5,6,5.5,2,0,12,1278,1278],
      [1634,625,387,223,399,0,1634,0,0,4.3,4.3,4.3,4.3,2,0,12,7060,7060],
      [275,184,11,48,7,0,7,243,0,2.6,2.8,2.6,2.8,1,0,9,702,702],
      [458,202,66,75,115,0,458,0,0,2,2,2,2,1,0,16,903,903],
      [218,28,118,44,0,10,91,109,0,31,33.8,37.4,40.8,1,0,8,6765,8151],
      [498,107,132,7,77,122,445,0,0,16.5,18.5,16.5,18.5,3,0,19,8227,8227],
      [143,54,65,0,14,0,11,122,0,2.3,2.5,2.8,3,1,0,4,334,402],
      [722,163,0,202,237,20,622,0,0,5.8,6.7,5.8,6.7,1,0,9,4164,4164],
      [236,27,192,12,37,0,268,0,0,29,25.5,29,25.5,2,0,15,6844,6844],
      [239,39,70,18,62,55,244,0,0,6.9,6.8,6.9,6.8,2,0,10,1661,1661],
      [1882,711,589,218,442,0,1960,0,0,3.2,3.1,3.2,3.1,2,0,10,6068,6068],
      [291,188,29,0,69,37,323,0,0,20.8,18.8,22.4,20.2,2,0,14,6063,6519],
      [328,124,71,61,66,0,322,0,0,2,2.1,2,2.1,1,0,13,665,665],
      [264,126,7,50,84,0,267,0,0,2.1,2,2.1,2,1,0,6,544,544],
      [270,54,42,53,91,30,270,0,0,3.3,3.3,3.3,3.3,1,0,6,893,893],
      [32,0,7,12,0,10,29,0,0,11,12.1,11,12.1,1,0,2.5,352,352],
      [1382,353,245,7,581,253,1439,0,0,2.4,2.3,2.4,2.3,4,0,8,3344,3344],
      [98,45,5,19,28,0,94,3,0,4.1,4.2,5,5,1,0,1,404,487],
      [289,3,100,0,66,145,314,0,0,19.8,18.3,19.8,18.3,2,0,8,5732,5732],
      [1059,299,234,144,217,60,954,0,0,21.6,24,24.9,27.6,2,0,17,22920,26345],
      [724,331,12,189,164,0,530,142,24,13,13.5,15.7,16.3,1,0,9,9409,11336],
      [40,10,22,0,17,0,49,0,0,7.1,5.8,7.1,5.8,4,0,4,285,285],
      [128,72,18,24,7,0,4,117,0,10.1,10.7,12.2,12.9,1,0,3,1293,1558],
      [1248,249,262,146,423,15,1095,0,0,12.2,13.8,12.2,13.8,4,0,12,15165,15165],
      [387,109,118,67,90,7,391,0,0,8.5,8.4,10.2,10.1,1,0,17,3287,3960],
      [73,0,65,0,0,5,19,44,7,10.5,10.9,12.6,13.1,1,0,3,764,920],
      [151,22,0,68,47,0,32,105,0,14.5,16,17.5,19.3,1,0,3,2194,2643],
      [465,48,162,0,196,37,443,0,0,4.3,4.5,5.2,5.5,1,0,4,2014,2427],
      [63,29,0,9,24,0,62,0,0,13.1,13.3,15.8,16.1,1,0,4,827,996],
      [226,88,70,19,28,0,92,106,7,11.1,12.2,11.1,12.2,1,0,10,2508,2508],
      [115,76,11,28,0,0,10,105,0,1.7,1.7,1.7,1.7,1,0,1.5,201,201],
      [189,39,112,3,28,0,0,182,0,3,3.1,3,3.1,2,0,15,563,563],
      [55,52,0,6,0,0,58,0,0,9.7,9.2,11.7,11.1,1,0,11,534,643],
      [85,12,44,0,24,0,12,68,0,12.2,13,14.7,15.7,1,0,4,1039,1252],
      [2143,219,657,3,485,437,1801,0,0,20.2,24,24.3,29,1,0,7,43303,52172],
      [520,181,160,9,55,25,430,0,0,6,7.3,6,7.3,2,0,8,3133,3133],
      [113,25,34,16,27,0,38,64,0,15.9,17.7,18.3,20.3,2,0,3,1801,2070],
      [264,85,17,26,133,0,157,98,6,10,10.1,12,12.2,1,0,6,2639,3180],
      [349,162,24,18,112,30,342,4,0,6.8,6.8,6.8,6.8,2,0,4,2360,2360],
      [229,88,5,0,17,131,241,0,0,11,10.5,12.7,12,2,0,5,2520,2897],
      [172,88,40,4,30,7,169,0,0,10.4,10.6,10.4,10.6,4,0,5,1788,1788],
      [323,108,57,53,74,31,323,0,0,3.8,3.8,3.8,3.8,1,0,13,1238,1238],
      [89,15,28,17,7,30,24,73,0,5,4.6,5,4.6,2,0,4,442,442],
      [878,113,404,161,133,17,828,0,0,3.8,4.1,4.3,4.5,1,0,5,3368,3742],
      [220,81,50,51,42,0,224,0,0,1.3,1.3,1.3,1.3,3,0,3,281,281],
      [150,125,4,20,0,0,6,143,0,4.6,4.6,5.5,5.6,1,0,3,687,828],
      [161,60,38,30,41,0,169,0,0,1.4,1.3,1.4,1.3,1,0,2,220,220],
      [804,345,334,0,236,42,957,0,0,14.2,11.9,17.1,14.3,1,0,12,11388,13720],
      [272,63,20,61,71,30,245,0,0,35.7,39.7,41.1,45.6,2,0,14,9720,11172],
      [33,8,7,0,10,15,32,8,0,4.4,3.6,4.4,3.6,2,0,2,145,145],
      [64,20,28,10,7,0,65,0,0,2.2,2.2,2.2,2.2,2,0,3,140,140],
      [277,48,110,47,49,0,84,170,0,4.6,5,4.6,5,2,0,19,1265,1265],
      [322,78,100,67,54,0,179,106,14,16.3,17.5,19.6,21.1,1,0,13,5242,6316],
      [164,52,56,18,7,20,110,43,0,17,18.2,17,18.2,2,0,11,2791,2791],
      [145,48,10,72,14,0,144,0,0,5.1,5.2,6.2,6.2,1,0,3,742,894],
      [73,36,24,12,0,0,0,72,0,8,8.1,9.6,9.8,1,0,5,584,704],
      [245,42,179,24,42,15,302,0,0,3.6,3,3.6,3,2,0,7,893,893],
      [406,209,36,125,20,0,102,288,0,13.9,14.5,16.7,17.4,1,0,7,5639,6794],
      [98,35,0,41,20,0,28,68,0,56.5,57.6,68,69.4,1,0,5,5533,6666],
      [83,44,10,3,25,0,15,63,4,4.9,5,6,6,1,0,3,410,494],
      [182,30,59,39,29,0,0,157,0,5.5,6.4,6.6,7.7,1,0,5,1001,1206],
      [820,460,98,199,175,0,685,212,35,3.1,2.7,3.1,2.7,4,0,11,2552,2552],
      [545,116,226,131,72,0,79,466,0,16,16,16,16,1,0,11,8740,8740],
      [105,96,9,0,0,0,21,84,0,1.9,1.9,1.9,1.9,1,0,8,198,198],
      [55,12,10,14,15,0,9,42,0,42.7,46,51.4,55.5,1,0,1,2347,2828],
      [62,27,4,0,31,7,69,0,0,13.2,11.8,15.9,14.3,1,0,8,817,984],
      [109,0,105,0,0,0,0,105,0,2.3,2.4,2.8,2.9,1,0,1,249,300],
      [436,27,334,15,0,60,436,0,0,17.8,17.8,17.8,17.8,2,0,15,7762,7762],
      [179,60,44,6,38,40,188,0,0,4.3,4.1,5.2,5,1,0,4,776,935],
      [1710,932,521,233,214,0,1900,0,0,7.7,6.9,7.7,6.9,2,0,21,13130,13130],
      [128,49,15,25,31,0,120,0,0,12.8,13.7,14.8,15.8,2,0,2,1644,1890],
      [174,21,7,30,50,32,140,0,0,77.7,96.6,77.7,96.6,4,0,8,13528,13528],
      [70,28,4,15,21,0,39,29,0,8.8,9.1,10.6,10.9,1,0,5,617,743],
      [379,159,29,57,119,15,379,0,0,6.3,6.3,6.3,6.3,1,0,7,2391,2391],
      [258,12,16,230,0,0,26,232,0,2.3,2.3,2.3,2.3,2,0,5,605,605],
      [129,33,0,39,24,25,121,0,0,16,17.1,18.4,19.6,2,0,4,2064,2372],
      [856,349,194,74,84,155,856,0,0,3,3,3,3,2,0,12,2551,2551],
      [127,56,14,10,39,0,25,94,0,13.1,14,15.8,16.9,1,0,7,1668,2010],
      [381,119,107,9,28,65,137,191,0,4.8,5.5,4.8,5.5,2,0,19,1817,1817],
      [234,117,19,93,0,5,231,3,0,21.8,21.8,21.8,21.8,1,0,10,5103,5103],
      [215,58,62,46,51,0,82,135,0,13.2,13.1,15.9,15.7,1,0,8,2836,3417],
      [1406,541,70,290,335,90,1326,0,0,10.6,11.3,10.5,11.1,4,0,1,14938,14698],
      [85,21,67,3,0,15,22,59,25,12.3,9.9,12.3,9.9,2,0,13,1049,1049],
      [59,10,32,3,21,5,71,0,0,18,14.9,21.7,18,1,0,10,1061,1278],
      [358,139,0,89,70,40,338,0,0,38.9,41.2,46.8,49.6,1,0,9,13919,16770],
      [73,40,0,12,10,0,0,62,0,50.3,59.3,60.7,71.4,1,0,7,3675,4428],
      [597,189,96,78,239,7,609,0,0,4.3,4.2,4.3,4.2,1,0,6,2542,2542],
      [276,90,120,34,14,0,101,139,18,8.1,8.7,8.1,8.7,1,0,2,2244,2244],
      [728,181,165,15,84,167,330,27,255,11.1,13.1,13.3,15.8,1,0,4,8046,9694],
      [59,0,55,0,0,0,11,11,33,83.8,89.9,101,108.3,1,0,6,4945,5958],
      [98,36,32,9,17,0,45,42,7,13.4,14,16.1,16.8,1,0,11,1313,1582],
      [756,452,66,127,84,5,302,320,112,4.3,4.4,4.3,4.4,1,0,7,3214,3214],
      [155,120,34,0,0,0,47,107,0,3.1,3.1,3.8,3.8,1,0,10,483,582],
      [544,125,104,107,133,0,107,362,0,4.2,4.9,5.1,5.9,1,0,4,2306,2778],
      [813,27,677,34,0,100,18,820,0,2,1.9,2,1.9,2,0,9,1634,1634],
      [75,23,0,30,27,14,94,0,0,9.6,7.7,9.6,7.7,1,0,6,720,720],
      [112,85,4,16,14,0,119,0,0,9.6,9,9.6,9,4,0,13,1073,1073],
      [211,73,32,79,22,5,111,100,0,16.9,16.9,16.9,16.9,1,0,13,3566,3566],
      [895,222,271,222,63,0,778,0,0,0.9,1,0.9,1,1,0,7,780,780],
      [74,18,7,37,7,5,74,0,0,54,54,54,54,1,0,14,3995,3995],
      [3331,1049,519,399,595,360,2922,0,0,14.7,16.8,14.7,16.8,4,0,42,49034,49034],
      [64,15,18,9,15,5,12,39,11,6.1,6.3,7.4,7.6,1,0,6,392,472],
      [1402,328,804,187,49,63,1431,0,0,12.6,12.3,12.3,12,1,0,23,17607,17219],
      [337,128,21,86,77,25,337,0,0,1.8,1.8,1.9,1.9,1,0,8,591,657],
      [73,0,0,67,0,10,39,38,0,11.1,10.5,13.4,12.7,1,0,6,812,978],
      [64,12,28,17,7,0,47,17,0,8.8,8.8,10.6,10.6,1,0,12,564,680],
      [1703,186,463,0,516,316,1481,0,0,5,5.8,5,5.8,3,0,8,8549,8549],
      [151,41,21,29,41,19,151,0,0,2.6,2.6,2.9,2.9,1,0,3,391,434],
      [66,27,14,6,17,0,42,22,0,27.5,28.4,33.2,34.2,1,0,2,1817,2189],
      [70,24,0,3,42,5,74,0,0,7.7,7.3,9.4,8.9,2,0,3,540,659],
      [754,301,130,204,90,0,213,512,0,9.9,10.3,11.9,12.4,1,0,8,7443,8967],
      [325,106,49,31,80,12,136,142,0,26.7,31.2,32.1,37.5,1,0,6,8663,10437],
      [168,84,7,45,40,22,198,0,0,27.5,23.3,27.5,23.3,2,0,12,4622,4622],
      [226,99,50,43,63,5,260,0,0,4,3.5,4,3.5,4,0,7,915,915],
      [335,83,71,71,111,17,353,0,0,75.8,72,75.8,72,4,0,12,25401,25401],
      [76,21,51,3,0,0,63,12,0,7.5,7.6,9,9.1,1,0,5,569,686],
      [221,31,133,0,45,5,53,161,0,6.8,7.1,8.2,8.5,1,0,4,1512,1822],
      [1010,213,224,111,212,75,758,77,0,5,6.1,5,6.1,2,0,11,5053,5053],
      [116,46,12,22,35,15,130,0,0,16.7,14.9,16.7,14.9,1,0,10,1939,1939],
      [39,25,0,3,14,0,11,31,0,2.9,2.7,2.9,2.7,2,0,1,114,114],
      [170,75,12,23,39,0,108,41,0,9,10.3,9,10.3,4,0,8,1532,1532],
      [179,85,0,49,59,0,193,0,0,26.4,24.5,31.8,29.5,1,0,4,4723,5690],
      [166,126,0,38,0,0,0,164,0,17.9,18.1,21.6,21.8,1,0,13,2971,3580],
      [354,48,34,174,73,25,354,0,0,16.5,16.5,16.5,16.5,1,0,10,5841,5841],
      [615,546,0,74,7,0,627,0,0,1.5,1.5,1.5,1.5,2,0,8,941,941],
      [126,46,7,18,49,15,135,0,0,8.2,7.7,8.2,7.7,2,0,8,1035,1035],
      [1390,379,377,133,182,170,1241,0,0,4,4.5,4,4.5,3,0,13,5597,5597],
      [129,30,59,10,39,0,94,44,0,23.2,21.7,27.9,26.1,1,0,8,2988,3600],
      [203,35,48,6,14,100,203,0,0,15.9,15.9,15.9,15.9,1,0,5,3219,3219],
      [758,116,312,132,30,58,648,0,0,6.1,7.1,6.1,7.1,1,0,15,4630,4630],
      [558,92,116,57,196,0,461,0,0,7.4,8.9,7.4,8.9,1,0,6,4112,4112],
      [25,14,0,4,7,0,22,0,3,23.2,23.2,23.2,23.2,1,0,6,580,580],
      [850,94,348,205,45,74,320,446,0,12.9,14.3,15.5,17.2,1,0,5,10942,13183],
      [235,78,10,123,68,0,13,82,184,4,3.4,4.8,4,1,0,9,937,1129],
      [58,15,0,19,22,0,26,30,0,43.4,44.9,52.2,54.1,1,0,8,2515,3030],
      [316,14,118,14,155,0,139,151,11,8.2,8.6,8.2,8.6,2,0,8,2600,2600],
      [7633,1240,2455,135,1732,1572,1376,5193,565,3.3,3.5,3.3,3.5,2,0,19,25217,25217],
      [119,0,118,0,0,0,95,19,4,1.5,1.5,1.8,1.8,1,0,2,176,212],
      [55,12,17,6,14,10,59,0,0,6.2,5.8,7.5,7,1,0,3,341,411],
      [1644,240,858,177,91,115,1481,0,0,9.9,11,9.9,11,1,0,38,16357,16357],
      [1193,196,667,149,115,54,516,485,180,2.5,2.5,3,3.1,1,0,12,3006,3622],
      [605,155,231,91,105,0,582,0,0,2.8,2.9,3.4,3.5,1,0,8,1694,2041],
      [389,120,94,77,63,10,198,166,0,2.9,3.1,2.9,3.1,2,0,6,1134,1134],
      [132,56,0,27,38,7,128,0,0,9,9.3,10.8,11.2,1,0,8,1186,1429],
      [132,30,50,22,24,0,39,27,60,10.5,11,12.6,13.2,1,0,9,1383,1666],
      [286,94,36,44,38,55,267,0,0,6,6.5,6,6.5,1,0,6,1727,1727],
      [305,73,87,39,63,10,272,0,0,14.8,16.6,14.8,16.6,3,0,7,4504,4504],
      [268,73,105,0,70,0,248,0,0,17.9,19.4,20.6,22.2,2,0,8,4800,5517],
      [110,36,15,0,49,10,110,0,0,23.2,23.2,23.2,23.2,2,0,24,2553,2553],
      [3963,1184,616,952,1091,42,3885,0,0,4.3,4.4,4.3,4.4,2,0,11,16921,16921],
      [397,83,252,16,58,0,409,0,0,18.8,18.2,22.6,22,1,0,7,7459,8987],
      [254,90,39,3,117,0,119,100,30,15.3,15.6,15.3,15.6,2,0,11,3877,3877],
      [134,73,0,22,14,0,33,76,0,15.6,19.2,18.8,23.1,1,0,8,2088,2516],
      [266,101,70,26,56,5,258,0,0,17.7,18.2,21.3,21.9,1,0,8,4695,5657],
      [237,114,11,44,42,0,181,30,0,13.5,15.2,16.3,18.3,1,0,9,3201,3857],
      [1243,555,15,245,394,10,1219,0,0,9.2,9.4,11.1,11.4,1,0,9,11490,13843],
      [666,138,233,124,105,5,605,0,0,1.1,1.2,1.1,1.2,1,0,13,752,752],
      [1810,349,423,377,457,10,1616,0,0,16.2,18.2,16.2,18.2,3,0,35,29399,29399],
      [88,56,7,15,7,0,9,76,0,26.1,27,31.5,32.6,1,0,6,2299,2770],
      [62,19,8,9,15,0,51,0,0,14.2,17.3,15.3,18.6,1,0,5,883,949],
      [305,59,102,19,60,21,138,123,0,28.5,33.3,34.4,40.2,1,0,10,8702,10484],
      [349,107,93,97,52,0,286,63,0,10.6,10.6,10.6,10.6,1,0,8,3703,3703],
      [156,0,133,0,10,0,143,0,0,4.5,4.9,5.4,5.9,1,0,4,705,849],
      [100,24,76,3,7,0,40,70,0,14.3,13,14.3,13,1,0,15,1434,1434],
      [222,20,5,93,73,0,47,144,0,11,12.8,13.3,15.5,1,0,4,2450,2952],
      [506,54,161,43,173,80,511,0,0,6.9,6.8,6.9,6.8,1,0,9,3500,3500],
      [123,28,0,47,15,25,115,0,0,15.4,16.5,17.7,18.9,2,0,3,1896,2179],
      [252,0,109,143,0,0,109,143,0,27.1,27.1,27.1,27.1,2,0,11,6821,6821],
      [258,186,40,19,10,0,0,255,0,5.4,5.5,6.5,6.6,1,0,4,1393,1678],
      [166,67,88,6,0,0,37,120,4,15.7,16.2,18.9,19.5,1,0,7,2604,3137],
      [181,45,39,38,42,5,169,0,0,20.1,21.5,22.6,24.2,2,0,10,3638,4088],
      [284,99,112,26,28,0,220,27,18,11.4,12.2,11.4,12.2,1,0,4,3234,3234],
      [52,0,60,0,0,0,0,55,5,4.8,4.2,5.8,5.1,1,0,3,252,304],
      [102,72,0,18,0,7,0,97,0,10.1,10.6,12.1,12.8,1,0,3,1028,1239],
      [58,26,29,3,0,0,22,36,0,11.9,11.9,14.4,14.4,1,0,5,691,833],
      [1196,626,108,56,413,5,1208,0,0,6.5,6.5,6.5,6.5,4,0,15,7824,7824],
      [38,30,0,8,0,0,32,0,6,6.5,6.5,6.5,6.5,1,0,4,247,247],
      [84,33,0,21,27,0,61,20,0,32.6,33.8,39.3,40.7,1,0,10,2738,3299],
      [73,18,14,8,44,0,40,44,0,15.4,13.3,18.5,16.1,1,0,6,1121,1351],
      [449,352,12,12,52,0,0,428,0,35.7,37.5,43,45.2,1,0,8,16042,19328],
      [551,188,116,52,114,5,223,231,21,4.4,5.1,5.3,6.2,1,0,13,2435,2934],
      [194,48,47,28,27,35,185,0,0,7.4,7.8,7.4,7.8,2,0,8,1440,1440],
      [185,36,14,50,32,10,142,0,0,34.7,45.2,34.7,45.2,1,0,16,6416,6416],
      [134,43,0,77,36,0,156,0,0,9.1,7.8,10.9,9.4,1,0,5,1213,1461],
      [1241,575,45,319,301,0,1240,0,0,8.2,8.2,8.2,8.2,1,0,15,10222,10222],
      [99,81,0,3,15,0,6,93,0,2.4,2.4,2.4,2.4,1,0,3,241,241],
      [1285,685,67,133,620,7,1512,0,0,0.9,0.8,0.9,0.8,1,0,16.5,1200,1200],
      [466,164,212,12,66,7,461,0,0,3.7,3.7,4.4,4.5,1,0,10,1708,2058],
      [77,30,0,20,22,0,7,65,0,27.4,29.3,33,35.3,1,0,4,2108,2540],
      [81,11,22,0,20,21,64,10,0,5.6,6.1,6.8,7.4,1,0,1,454,547],
      [694,61,164,168,145,60,598,0,0,5.9,6.8,5.9,6.8,4,0,8,4086,4086],
      [62,18,7,6,10,17,7,51,0,32.7,34.9,39.4,42.1,1,0,5,2027,2442],
      [56,0,42,0,0,15,57,0,0,5.2,5.1,5.2,5.1,1,0,3,293,293],
      [753,289,13,0,363,7,672,0,0,5.7,6.4,5.7,6.4,1,0,12,4301,4301],
      [421,177,22,217,0,5,421,0,0,39.9,39.9,39.9,39.9,1,0,15.5,16788,16788],
      [59,30,11,3,21,0,65,0,0,9.6,8.7,11.6,10.5,1,0,3,566,682],
      [409,42,201,39,67,60,409,0,0,6.5,6.5,6.5,6.5,2,0,11,2672,2672],
      [115,21,90,4,0,0,94,21,0,16.3,16.3,16.3,16.3,2,0,12,1869,1869],
      [93,58,20,4,10,0,22,70,0,8.6,8.7,10.4,10.5,1,0,3,803,967],
      [71,30,15,12,7,5,0,69,0,56.6,58.2,68.2,70.2,1,0,7,4019,4842],
      [971,345,42,249,150,10,796,0,0,5,6.1,6,7.4,1,0,14,4867,5864],
      [74,15,7,42,0,10,74,0,0,42.3,42.3,42.3,42.3,1,0,17,3132,3132],
      [81,18,4,25,21,10,25,30,23,1.1,1.1,1.3,1.4,1,0,1,89,107],
      [106,6,33,19,0,55,113,0,0,10.6,10,12.8,12,1,0,7,1126,1357],
      [1168,516,240,176,314,10,1256,0,0,1.3,1.2,1.3,1.2,3,0,8,1538,1538],
      [1093,392,119,235,166,47,959,0,0,6.6,7.6,6.6,7.6,1,0,11,7263,7263],
      [67,10,18,31,0,0,0,59,0,57.5,65.3,69.3,78.7,1,0,2,3853,4642],
      [1256,270,121,450,90,50,981,0,0,23,29.4,41,52.5,1,0,28,28855,51527],
      [72,67,5,0,0,0,6,66,0,17.3,17.3,20.9,20.9,1,0,15,1248,1504],
      [777,287,159,38,147,45,676,0,0,19.4,22.2,22.2,25.6,2,0,13,15039,17286],
      [131,30,33,18,35,12,128,0,0,37.8,38.6,45.5,46.6,1,0,13,4947,5960],
      [134,78,0,0,63,0,141,0,0,15.1,14.3,18.2,17.3,1,0,8,2019,2433],
      [826,255,295,72,157,0,779,0,0,6.5,6.9,6.5,6.9,1,0,42,5400,5400],
      [3180,916,538,295,969,0,2718,0,0,10.4,12.2,10.4,12.2,4,0,36,33028,33028],
      [324,175,108,29,17,5,334,0,0,15.7,15.2,15.7,15.2,1,0,13,5078,5078],
      [220,132,45,30,7,0,49,165,0,3.2,3.3,3.2,3.3,1,0,3,701,701],
      [258,34,89,6,63,49,241,0,0,2.9,3.1,2.9,3.1,1,0,12,736,736],
      [139,25,19,6,29,60,139,0,0,7,7,7,7,2,0,7,976,976],
      [274,70,123,57,28,30,308,0,0,4.3,3.8,4.3,3.8,2,0,4,1167,1167],
      [231,0,86,0,50,130,266,0,0,16.3,14.1,16.3,14.1,4,0,12,3762,3762],
      [126,58,15,6,21,40,22,118,0,4.9,4.4,4.9,4.4,2,0,5,619,619],
      [93,0,70,0,15,10,0,95,0,11.8,11.6,14.3,14,1,0,8,1101,1327],
      [1825,594,569,192,259,60,1674,0,0,0.7,0.7,0.7,0.7,1,0,15,1210,1210],
      [500,229,31,130,60,0,170,227,53,11.8,13.1,14.2,15.7,1,0,8,5876,7080],
      [373,129,96,21,105,50,389,12,0,6.4,6,6.4,6,2,0,10,2395,2395],
      [330,179,26,64,110,0,379,0,0,3.2,2.8,3.2,2.8,1,0,10,1050,1050],
      [57,27,28,0,0,0,0,55,0,30.5,31.7,36.8,38.1,1,0,4,1741,2098],
      [127,61,0,20,44,0,13,98,14,12.4,12.6,15,15.2,1,0,4,1579,1902],
      [1362,579,291,171,378,0,1419,0,0,2.3,2.3,2.3,2.3,3,0,11,3193,3193],
      [1463,780,119,223,371,0,1493,0,0,24.6,24.1,24.6,24.1,4,0,23,36046,36046],
      [148,12,49,36,28,15,140,0,0,23.2,24.6,28,29.6,1,0,3,3437,4141],
      [474,71,24,343,21,15,41,433,0,3.9,3.9,3.9,3.9,1,0,6,1829,1829],
      [77,24,18,21,14,0,18,59,0,5.3,5.3,6.4,6.4,1,0,10,408,492],
      [213,105,67,41,0,0,52,161,0,3.8,3.8,3.8,3.8,1,0,2.5,801,801],
      [175,22,53,0,100,0,59,116,0,3.4,3.4,3.4,3.4,2,0,7,597,597],
      [360,122,98,54,62,0,336,0,0,2.1,2.3,2.1,2.3,1,0,18,763,763],
      [331,84,0,12,0,284,156,96,128,3.7,3.3,3.7,3.3,2,0,5,1238,1238],
      [285,48,187,15,35,25,310,0,0,4.4,4,4.4,4,2,0,7,1249,1249],
      [187,72,32,10,44,5,4,159,0,73.5,84.4,84.5,97,2,0,3,13752,15807],
      [502,120,32,89,83,120,444,0,0,18.5,20.9,18.5,20.9,1,0,14,9296,9296],
      [303,0,266,0,0,25,0,291,0,1.1,1.1,1.3,1.4,1,0,1,329,396],
      [174,105,83,0,0,5,98,35,60,17.7,16,17.7,16,2,0,17,3088,3088],
      [44,14,0,16,17,5,49,3,0,8.6,7.3,8.6,7.3,4,0,2,380,380],
      [387,88,221,37,34,0,18,362,0,6,6.1,7.3,7.4,1,0,7,2333,2811],
      [406,18,374,27,0,0,21,398,0,5.2,5,5.2,5,2,0,19,2109,2109],
      [496,198,109,67,90,60,524,0,0,20.3,19.2,23.4,22.1,2,0,14,10080,11586],
      [116,34,38,4,30,0,33,73,0,4.8,5.2,4.8,5.2,1,0,2,553,553],
      [53,17,17,0,24,5,63,0,0,6.7,5.6,6.7,5.6,2,0,16,354,354],
      [209,42,145,10,43,0,225,15,0,0.9,0.8,0.9,0.8,1,0,2.5,190,190],
      [903,336,134,158,148,100,387,303,186,6.1,6.3,7.3,7.5,1,0,11,5482,6605],
      [469,71,170,15,67,96,419,0,0,6.8,7.6,8.2,9.2,1,0,11,3191,3845],
      [1894,187,1241,143,156,10,966,696,75,2.1,2.3,2.1,2.3,2,0,12,3986,3986],
      [215,108,0,94,7,0,76,133,0,2.6,2.7,2.6,2.7,1,0,7,560,560],
      [82,38,9,20,14,0,29,52,0,1,1,1.2,1.2,1,0,2,80,96],
      [1694,391,469,385,210,85,1540,0,0,4.6,5.1,4.6,5.1,1,0,16,7816,7816],
      [81,24,22,20,10,0,64,4,8,24.7,26.3,29.8,31.7,1,0,5,2002,2412],
      [297,150,7,132,0,0,13,264,12,5.2,5.4,5.2,5.4,1,0,6,1557,1557],
      [280,161,91,0,10,0,262,0,0,5.1,5.4,5.1,5.4,4,0,7,1417,1417],
      [56,19,5,16,10,0,29,21,0,22.3,24.9,26.8,30,1,0,5,1246,1501],
      [492,114,97,157,49,75,248,244,0,8.5,8.5,8.5,8.5,1,0,11,4158,4158],
      [426,127,122,54,87,20,31,352,27,1.5,1.6,1.8,1.9,1,0,2,646,778],
      [499,262,42,60,90,0,155,299,0,4.6,5.1,4.6,5.1,1,0,10,2310,2310],
      [60,9,32,12,7,0,60,0,0,16.5,16.5,18.4,18.4,1,0,5,992,1102],
      [362,152,68,41,72,15,348,0,0,19.6,20.4,23.6,24.5,1,0,6,7091,8543],
      [363,169,23,115,42,0,82,267,0,9.5,9.8,11.4,11.8,1,0,5,3431,4134],
      [53,24,0,24,0,0,0,48,0,19,21,22.9,25.3,1,0,3,1007,1213],
      [17518,9404,1221,0,2955,0,13580,0,0,3.1,4,3.1,4,1,0,14,54620,54620],
      [199,82,92,13,10,0,20,100,77,4.4,4.4,5.3,5.3,1,0,2,871,1049],
      [2171,534,319,323,87,0,209,984,70,9.1,15.6,9.1,15.6,1,0,8,19699,19699],
      [220,90,19,64,39,0,12,200,0,8.8,9.1,10.6,11,1,0,4,1930,2325],
      [1355,535,428,58,224,10,1255,0,0,5.5,6,5.5,6,1,0,26,7505,7505],
      [374,170,4,88,126,10,398,0,0,0.8,0.8,1,0.9,1,0,2,300,363],
      [62,51,0,0,10,5,66,0,0,5.6,5.3,6.8,6.4,1,0,3,349,420],
      [311,11,217,3,36,57,324,0,0,6.6,6.3,7.9,7.6,1,0,6,2038,2455],
      [132,32,15,13,31,45,136,0,0,4.6,4.4,5.5,5.3,1,0,6,601,724],
      [135,60,17,0,70,0,0,147,0,4.9,4.5,4.9,4.5,2,0,15,667,667],
      [79,16,34,0,28,10,81,7,0,45.4,40.7,54.7,49.1,1,0,5,3585,4319],
      [155,75,28,10,29,0,14,128,0,12.4,13.5,14.9,16.3,1,0,4,1916,2308],
      [965,433,234,148,245,0,1060,0,0,3.8,3.4,4.1,3.7,1,0,30,3655,3930],
      [296,27,166,48,21,50,312,0,0,18.4,17.4,18.4,17.4,2,0,10,5432,5432],
      [56,3,19,10,24,0,56,0,0,3,3,3,3,2,0,3,170,170],
      [206,88,23,31,35,0,73,104,0,8.8,10.3,10.7,12.4,1,0,8,1823,2196],
      [651,104,385,16,49,27,581,0,0,5.5,6.2,6.7,7.5,1,0,4,3612,4352],
      [2323,804,332,0,947,240,636,1552,135,1.7,1.7,1.7,1.7,2,0,6,3981,3981],
      [146,46,0,50,41,0,44,93,0,13.6,14.5,16.4,17.4,1,0,6,1984,2390],
      [284,49,83,75,51,5,80,183,0,12.8,13.9,15.5,16.7,1,0,5,3646,4393],
      [249,47,26,80,84,0,237,0,0,15.3,16,15.3,16,2,0,9,3800,3800],
      [32,4,7,0,0,30,41,0,0,15.6,12.1,15.6,12.1,1,0,3,498,498],
      [1908,401,1216,155,107,10,1889,0,0,14.2,14.3,14.2,14.3,3,0,48,27000,27000],
      [253,56,149,0,24,24,76,177,0,6.7,6.7,6.7,6.7,1,0,7,1694,1694],
      [184,53,21,43,38,15,170,0,0,16,17.4,18.4,20,2,0,4,2952,3393],
      [76,60,12,0,0,0,0,72,0,4.9,5.2,5.9,6.3,1,0,1,374,451],
      [276,108,5,75,56,0,177,53,14,1.1,1.2,1.1,1.2,1,0,4,300,300],
      [3471,1327,257,534,995,42,3155,0,0,2.2,2.4,2.2,2.4,4,0,17,7575,7575],
      [380,67,103,77,98,20,365,0,0,8.7,9.1,10.5,11,1,0,9,3322,4002],
      [155,18,0,69,14,47,148,0,0,33.5,35.1,33.5,35.1,1,0,8,5196,5196],
      [327,64,142,21,0,100,327,0,0,7.8,7.8,7.8,7.8,2,0,16,2566,2566],
      [193,82,80,50,14,0,41,182,3,8.7,7.5,10.5,9,1,0,5,1686,2031],
      [1108,279,20,314,273,30,916,0,0,22.6,27.4,24.3,29.4,1,0,6,25054,26940],
      [363,168,10,92,77,5,0,352,0,0.3,0.3,0.4,0.4,1,0,10,117,141],
      [249,144,104,6,14,0,268,0,0,2,1.9,2,1.9,1,0,3,500,500],
      [769,265,195,235,52,0,178,557,12,16.3,16.8,16.3,16.8,1,0,8,12551,12551],
      [137,54,42,30,7,0,97,36,0,2.9,3,2.9,3,1,0,3,399,399],
      [579,215,81,109,112,0,517,0,0,1.4,1.5,1.4,1.5,1,0,7,784,784],
      [133,39,0,41,24,20,124,0,0,15.9,17,18.3,19.6,2,0,6,2112,2428],
      [78,7,34,6,21,0,22,46,0,7.7,8.8,8.8,10.1,2,0,3,600,690],
      [101,12,31,3,50,0,65,28,3,4.5,4.7,4.5,4.7,1,0,1.5,450,450],
      [1222,503,333,173,150,5,1164,0,0,4.7,5,4.7,5,1,0,20,5800,5800],
      [1093,486,277,126,147,5,788,253,0,2.3,2.5,2.3,2.5,2,0,7,2565,2565],
      [222,41,57,0,99,25,222,0,0,10.7,10.6,10.7,10.6,2,0,4,2385,2385],
      [2067,1056,658,45,303,5,1510,557,0,5,5,5,5,2,0,21,10398,10398],
      [175,65,31,22,38,0,141,15,0,19.6,22,23.6,26.5,1,0,10,3434,4137],
      [230,180,12,41,14,0,247,0,0,1.7,1.6,6,5.6,1,0,3,400,1379],
      [104,32,5,40,28,10,115,0,0,3.3,2.9,4.9,4.5,4,0,2,338,512],
      [177,24,79,6,42,60,211,0,0,16,13.4,16,13.4,2,0,17,2835,2835],
      [62,33,0,12,10,0,22,33,0,9.6,10.8,11.5,13,1,0,2,594,716],
      [487,146,238,53,24,12,45,428,0,2.1,2.2,2.1,2.2,1,0,6,1017,1017],
      [177,40,12,27,38,60,177,0,0,4.5,4.5,5.4,5.4,1,0,8,789,951],
      [105,34,66,10,37,15,162,0,0,7.4,4.8,7.4,4.8,1,0,3,774,774],
      [140,43,68,3,57,0,171,0,0,4.6,3.7,4.6,3.7,4,0,1.5,640,640],
      [230,81,49,37,58,0,225,0,0,2.2,2.2,2.2,2.2,1,0,4,500,500],
      [236,102,84,52,0,0,238,0,0,2.5,2.5,2.8,2.8,1,0,10,601,668],
      [846,322,56,112,234,5,729,0,0,19.1,22.2,19.1,22.2,1,0,13,16179,16179],
      [139,18,21,30,70,0,139,0,0,17.6,17.6,17.6,17.6,2,0,6,2446,2446],
      [51,12,27,0,0,7,7,39,0,6.6,7.3,6.6,7.3,1,0,3,338,338],
      [195,57,32,12,140,0,241,0,0,9.2,7.4,11,8.9,1,0,9,1786,2152],
      [51,32,0,16,7,0,0,55,0,17.6,16.3,21.2,19.7,1,0,3,899,1083],
      [1106,410,267,108,152,25,962,0,0,15,17.2,17.2,19.8,2,0,20,16560,19034],
      [99,13,32,3,42,5,95,0,0,5.3,5.5,6.4,6.7,1,0,4,526,634],
      [56,24,0,9,14,0,47,0,0,7.9,9.4,7.9,9.4,2,0,6,440,440],
      [213,123,91,28,0,0,36,206,0,10.3,9,10.3,9,1,0,7,2185,2185]
    ]
    )

def nasa93(opt=options(),tunings=tunings()):
  vl=1;l=2;n=3;h=4;vh=5;xh=6
  return Thing(
    sfem=21,
    kloc=22,
    effort=23,
    names= [ 
     # 0..8
     'Prec', 'Flex', 'Resl', 'Team', 'Pmat', 'rely', 'data', 'cplx', 'ruse',
     # 9 .. 17
     'docu', 'time', 'stor', 'pvol', 'acap', 'pcap', 'pcon', 'aexp', 'plex',  
     # 18 .. 25
     'ltex', 'tool', 'site', 'sced', 'kloc', 'effort', '?defects', '?months'],
    projects=[
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,25.9,117.6,808,15.3],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,24.6,117.6,767,15.0],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,7.7,31.2,240,10.1],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,8.2,36,256,10.4],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,9.7,25.2,302,11.0],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,2.2,8.4,69,6.6],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,3.5,10.8,109,7.8],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,66.6,352.8,2077,21.0],
	[h,h,h,vh,h,h,l,h,n,n,xh,xh,l,h,h,n,h,n,h,h,n,n,7.5,72,226,13.6],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,vh,n,vh,n,h,n,n,n,20,72,566,14.4],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,h,n,vh,n,h,n,n,n,6,24,188,9.9],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,vh,n,vh,n,h,n,n,n,100,360,2832,25.2],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,n,n,vh,n,l,n,n,n,11.3,36,456,12.8],
	[h,h,h,vh,n,n,l,h,n,n,n,n,h,h,h,n,h,l,vl,n,n,n,100,215,5434,30.1],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,h,n,vh,n,h,n,n,n,20,48,626,15.1],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,n,n,n,n,vl,n,n,n,100,360,4342,28.0],
	[h,h,h,vh,n,n,l,h,n,n,n,xh,l,h,vh,n,vh,n,h,n,n,n,150,324,4868,32.5],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,h,n,h,n,h,n,n,n,31.5,60,986,17.6],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,h,h,n,vh,n,h,n,n,n,15,48,470,13.6],
	[h,h,h,vh,n,n,l,h,n,n,n,xh,l,h,n,n,h,n,h,n,n,n,32.5,60,1276,20.8],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,19.7,60,614,13.9],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,66.6,300,2077,21.0],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,29.5,120,920,16.0],
	[h,h,h,vh,n,h,n,n,n,n,h,n,n,n,h,n,h,n,n,n,n,n,15,90,575,15.2],
	[h,h,h,vh,n,h,n,h,n,n,n,n,n,n,h,n,h,n,n,n,n,n,38,210,1553,21.3],
	[h,h,h,vh,n,n,n,n,n,n,n,n,n,n,h,n,h,n,n,n,n,n,10,48,427,12.4],
	[h,h,h,vh,h,n,vh,h,n,n,vh,vh,l,vh,n,n,h,l,h,n,n,l,15.4,70,765,14.5],
	[h,h,h,vh,h,n,vh,h,n,n,vh,vh,l,vh,n,n,h,l,h,n,n,l,48.5,239,2409,21.4],
	[h,h,h,vh,h,n,vh,h,n,n,vh,vh,l,vh,n,n,h,l,h,n,n,l,16.3,82,810,14.8],
	[h,h,h,vh,h,n,vh,h,n,n,vh,vh,l,vh,n,n,h,l,h,n,n,l,12.8,62,636,13.6],
	[h,h,h,vh,h,n,vh,h,n,n,vh,vh,l,vh,n,n,h,l,h,n,n,l,32.6,170,1619,18.7],
	[h,h,h,vh,h,n,vh,h,n,n,vh,vh,l,vh,n,n,h,l,h,n,n,l,35.5,192,1763,19.3],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,5.5,18,172,9.1],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,10.4,50,324,11.2],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,14,60,437,12.4],
	[h,h,h,vh,n,h,n,h,n,n,n,n,n,n,n,n,n,n,n,n,n,n,6.5,42,290,12.0],
	[h,h,h,vh,n,n,n,h,n,n,n,n,n,n,n,n,n,n,n,n,n,n,13,60,683,14.8],
	[h,h,h,vh,h,n,n,h,n,n,n,n,n,n,h,n,n,n,h,h,n,n,90,444,3343,26.7],
	[h,h,h,vh,n,n,n,h,n,n,n,n,n,n,n,n,n,n,n,n,n,n,8,42,420,12.5],
	[h,h,h,vh,n,n,n,h,n,n,h,n,n,n,n,n,n,n,n,n,n,n,16,114,887,16.4],
	[h,h,h,vh,h,n,h,h,n,n,vh,h,l,h,h,n,n,l,h,n,n,l,177.9,1248,7998,31.5],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,h,n,n,n,n,n,n,n,302,2400,8543,38.4],
	[h,h,h,vh,h,n,h,l,n,n,n,n,h,h,n,n,h,n,n,h,n,n,282.1,1368,9820,37.3],
	[h,h,h,vh,h,h,h,l,n,n,n,n,n,h,n,n,h,n,n,n,n,n,284.7,973,8518,38.1],
	[h,h,h,vh,n,h,h,n,n,n,n,n,l,n,h,n,h,n,h,n,n,n,79,400,2327,26.9],
	[h,h,h,vh,l,l,n,n,n,n,n,n,l,h,vh,n,h,n,h,n,n,n,423,2400,18447,41.9],
	[h,h,h,vh,h,n,n,n,n,n,n,n,l,h,vh,n,vh,l,h,n,n,n,190,420,5092,30.3],
	[h,h,h,vh,h,n,n,h,n,n,n,h,n,h,n,n,h,n,h,n,n,n,47.5,252,2007,22.3],
	[h,h,h,vh,l,vh,n,xh,n,n,h,h,l,n,n,n,h,n,n,h,n,n,21,107,1058,21.3],
	[h,h,h,vh,l,n,h,h,n,n,vh,n,n,h,h,n,h,n,h,n,n,n,78,571.4,4815,30.5],
	[h,h,h,vh,l,n,h,h,n,n,vh,n,n,h,h,n,h,n,h,n,n,n,11.4,98.8,704,15.5],
	[h,h,h,vh,l,n,h,h,n,n,vh,n,n,h,h,n,h,n,h,n,n,n,19.3,155,1191,18.6],
	[h,h,h,vh,l,h,n,vh,n,n,h,h,l,h,n,n,n,h,h,n,n,n,101,750,4840,32.4],
	[h,h,h,vh,l,h,n,h,n,n,h,h,l,n,n,n,h,n,n,n,n,n,219,2120,11761,42.8],
	[h,h,h,vh,l,h,n,h,n,n,h,h,l,n,n,n,h,n,n,n,n,n,50,370,2685,25.4],
	[h,h,h,vh,h,vh,h,h,n,n,vh,vh,n,vh,vh,n,vh,n,h,h,n,l,227,1181,6293,33.8],
	[h,h,h,vh,h,n,h,vh,n,n,n,n,l,h,vh,n,n,l,n,n,n,l,70,278,2950,20.2],
	[h,h,h,vh,h,h,l,h,n,n,n,n,l,n,n,n,n,n,h,n,n,l,0.9,8.4,28,4.9],
	[h,h,h,vh,l,vh,l,xh,n,n,xh,vh,l,h,h,n,vh,vl,h,n,n,n,980,4560,50961,96.4],
	[h,h,h,vh,n,n,l,h,n,n,n,n,l,vh,vh,n,n,h,h,n,n,n,350,720,8547,35.7],
	[h,h,h,vh,h,h,n,xh,n,n,h,h,l,h,n,n,n,h,h,h,n,n,70,458,2404,27.5],
	[h,h,h,vh,h,h,n,xh,n,n,h,h,l,h,n,n,n,h,h,h,n,n,271,2460,9308,43.4],
	[h,h,h,vh,n,n,n,n,n,n,n,n,l,h,h,n,h,n,h,n,n,n,90,162,2743,25.0],
	[h,h,h,vh,n,n,n,n,n,n,n,n,l,h,h,n,h,n,h,n,n,n,40,150,1219,18.9],
	[h,h,h,vh,n,h,n,h,n,n,h,n,l,h,h,n,h,n,h,n,n,n,137,636,4210,32.2],
	[h,h,h,vh,n,h,n,h,n,n,h,n,h,h,h,n,h,n,h,n,n,n,150,882,5848,36.2],
	[h,h,h,vh,n,vh,n,h,n,n,h,n,l,h,h,n,h,n,h,n,n,n,339,444,8477,45.9],
	[h,h,h,vh,n,l,h,l,n,n,n,n,h,h,h,n,h,n,h,n,n,n,240,192,10313,37.1],
	[h,h,h,vh,l,h,n,h,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,144,576,6129,28.8],
	[h,h,h,vh,l,n,l,n,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,151,432,6136,26.2],
	[h,h,h,vh,l,n,l,h,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,34,72,1555,16.2],
	[h,h,h,vh,l,n,n,h,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,98,300,4907,24.4],
	[h,h,h,vh,l,n,n,h,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,85,300,4256,23.2],
	[h,h,h,vh,l,n,l,n,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,20,240,813,12.8],
	[h,h,h,vh,l,n,l,n,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,111,600,4511,23.5],
	[h,h,h,vh,l,h,vh,h,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,162,756,7553,32.4],
	[h,h,h,vh,l,h,h,vh,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,352,1200,17597,42.9],
	[h,h,h,vh,l,h,n,vh,n,n,n,vh,l,h,h,n,h,h,h,n,n,l,165,97,7867,31.5],
	[h,h,h,vh,h,h,n,vh,n,n,h,h,l,h,n,n,n,h,h,n,n,n,60,409,2004,24.9],
	[h,h,h,vh,h,h,n,vh,n,n,h,h,l,h,n,n,n,h,h,n,n,n,100,703,3340,29.6],
	[h,h,h,vh,n,h,vh,vh,n,n,xh,xh,h,n,n,n,n,l,l,n,n,n,32,1350,2984,33.6],
	[h,h,h,vh,h,h,h,h,n,n,vh,xh,h,h,h,n,h,h,h,n,n,n,53,480,2227,28.8],
	[h,h,h,vh,h,h,l,vh,n,n,vh,xh,l,vh,vh,n,vh,vl,vl,h,n,n,41,599,1594,23.0],
	[h,h,h,vh,h,h,l,vh,n,n,vh,xh,l,vh,vh,n,vh,vl,vl,h,n,n,24,430,933,19.2],
	[h,h,h,vh,h,vh,h,vh,n,n,xh,xh,n,h,h,n,h,h,h,n,n,n,165,4178.2,6266,47.3],
	[h,h,h,vh,h,vh,h,vh,n,n,xh,xh,n,h,h,n,h,h,h,n,n,n,65,1772.5,2468,34.5],
	[h,h,h,vh,h,vh,h,vh,n,n,xh,xh,n,h,h,n,h,h,h,n,n,n,70,1645.9,2658,35.4],
	[h,h,h,vh,h,vh,h,xh,n,n,xh,xh,n,h,h,n,h,h,h,n,n,n,50,1924.5,2102,34.2],
	[h,h,h,vh,l,vh,l,vh,n,n,vh,xh,l,h,n,n,l,vl,l,h,n,n,7.25,648,406,15.6],
	[h,h,h,vh,h,vh,h,vh,n,n,xh,xh,n,h,h,n,h,h,h,n,n,n,233,8211,8848,53.1],
	[h,h,h,vh,n,h,n,vh,n,n,vh,vh,h,n,n,n,n,l,l,n,n,n,16.3,480,1253,21.5],
	[h,h,h,vh,n,h,n,vh,n,n,vh,vh,h,n,n,n,n,l,l,n,n,n,  6.2, 12,477,15.4],
	[h,h,h,vh,n,h,n,vh,n,n,vh,vh,h,n,n,n,n,l,l,n,n,n,  3.0, 38,231,12.0],
	])


def coc81(opt=options(),tunings=tunings()):
  vl=1;l=2;n=3;h=4;vh=5;xh=6
  return Thing(
    sfem=21,
    kloc=22,
    effort=23,
    names= [
     'Prec', 'Flex', 'Resl', 'Team', 'Pmat', 'rely', 'data', 'cplx', 'ruse',
     'docu', 'time', 'stor', 'pvol', 'acap', 'pcap', 'pcon', 'aexp', 'plex',  
     'ltex', 'tool', 'site', 'sced', 'kloc', 'effort', '?defects', '?months'],
    projects=[
      [h,h,h,vh,vl,l,vh,vl,n,n,n,h,h,l,l,n,l,l,n,vl,h,n,113,2040,13027,38.4],
      [h,h,h,vh,vl,l,vh,l,n,n,n,h,n,n,n,n,h,h,h,vl,h,n,293,1600,25229,48.6],
      [h,h,h,vh,n,n,vh,l,n,n,n,n,l,h,h,n,vh,h,h,l,h,n,132,243,3694,28.7],
      [h,h,h,vh,vl,vl,vh,vl,n,n,n,n,l,l,vl,n,h,n,h,vl,h,n,60,240,5688,28.0],
      [h,h,h,vh,vl,l,l,n,n,n,n,n,l,n,h,n,n,h,h,vl,h,n,16,33,970,14.3],
      [h,h,h,vh,vl,vl,n,l,n,n,n,vh,n,vl,vl,n,n,h,h,vl,h,n,4,43,553,11.6],
      [h,h,h,vh,n,vl,n,n,n,n,n,n,l,n,n,n,n,h,h,l,h,n,6.9,8,350,10.3],
      [h,h,h,vh,vl,h,l,vh,n,n,xh,xh,vh,vh,n,n,h,vl,vl,vl,h,l,22,1075,3511,24.5],
      [h,h,h,vh,n,h,l,vh,n,n,vh,vh,h,h,h,n,n,l,l,vl,h,n,30,423,1989,24.1],
      [h,h,h,vh,l,vh,l,vh,n,n,h,xh,n,h,h,n,vh,h,n,vl,h,n,29,321,1496,23.2],
      [h,h,h,vh,l,vh,l,vh,n,n,h,xh,n,h,h,n,vh,h,n,vl,h,n,32,218,1651,24.0],
      [h,h,h,vh,n,h,l,vh,n,n,h,h,n,h,h,n,vh,n,h,vl,h,l,37,201,1783,19.1],
      [h,h,h,vh,n,h,l,vh,n,n,h,h,h,vh,vh,n,n,l,n,vl,h,n,25,79,1138,18.4],
      [h,h,h,vh,vl,h,l,xh,n,n,vh,xh,h,h,vh,n,n,l,l,vl,h,vl,3,60,387,9.4],
      [h,h,h,vh,n,vh,l,vh,n,n,vh,h,h,h,h,n,l,vl,vl,vl,h,vl,3.9,61,276,9.5],
      [h,h,h,vh,l,vh,n,vh,n,n,vh,xh,n,h,h,n,n,n,n,vl,h,n,6.1,40,390,14.9],
      [h,h,h,vh,l,vh,n,vh,n,n,vh,xh,n,h,h,n,vh,n,n,vl,h,n,3.6,9,230,12.3],
      [h,h,h,vh,vl,h,vh,h,n,n,vh,vh,n,h,n,n,n,n,n,vl,h,l,320,11400,34588,52.4],
      [h,h,h,vh,n,h,h,n,n,n,h,vh,l,vh,n,n,h,n,n,l,h,n,1150,6600,41248,67.0],
      [h,h,h,vh,vl,vh,h,vh,n,n,h,vh,h,vh,n,n,vh,l,l,vl,h,l,299,6400,30955,53.4],
      [h,h,h,vh,n,n,vh,h,n,n,n,n,l,h,n,n,n,n,n,l,h,n,252,2455,11664,40.8],
      [h,h,h,vh,n,h,n,n,n,n,n,h,n,h,h,n,vh,h,n,vl,h,vl,118,724,5172,21.7],
      [h,h,h,vh,l,h,n,n,n,n,n,h,n,h,h,n,vh,h,n,vl,h,vl,77,539,4362,19.5],
      [h,h,h,vh,n,l,n,l,n,n,n,h,n,n,n,n,vl,l,h,n,h,n,90,453,4407,27.1],
      [h,h,h,vh,n,h,vh,vh,n,n,n,h,n,h,h,n,n,l,n,l,h,l,38,523,2269,20.2],
      [h,h,h,vh,n,n,n,l,n,n,n,h,h,h,h,n,n,l,n,vl,h,l,48,387,2419,18.5],
      [h,h,h,vh,n,h,l,h,n,n,n,vh,n,n,n,n,n,n,n,vl,h,l,9.4,88,517,12.1],
      [h,h,h,vh,vl,h,h,vh,n,n,h,vh,h,h,h,n,n,l,l,vl,h,n,13,98,1473,19.6],
      [h,h,h,vh,n,l,n,n,n,n,n,n,n,n,h,n,vl,n,n,l,h,vl,2.14,7.3,138,5.3],
      [h,h,h,vh,n,l,n,n,n,n,n,n,n,n,h,n,vl,n,n,l,h,vl,1.98,5.9,128,5.2],
      [h,h,h,vh,l,vh,h,n,n,n,n,xh,h,h,h,n,vh,l,l,vl,h,n,62,1063,3682,32.8],
      [h,h,h,vh,vl,l,h,l,n,n,n,n,n,vh,n,n,vh,n,n,vl,h,n,390,702,30484,45.8],
      [h,h,h,vh,n,vh,h,vh,n,n,n,xh,h,h,h,n,vh,h,n,l,h,n,42,605,1803,27.1],
      [h,h,h,vh,n,h,h,n,n,n,n,n,n,n,n,n,n,n,n,vl,h,vl,23,230,1271,14.2],
      [h,h,h,vh,vl,vl,l,vh,n,n,n,vh,h,n,n,n,h,l,n,vl,h,n,13,82,2250,17.2],
      [h,h,h,vh,l,l,n,n,n,n,n,n,l,l,l,n,n,h,h,l,h,n,15,55,1004,15.8],
      [h,h,h,vh,l,l,l,vl,n,n,n,h,n,h,h,n,vh,n,n,vl,h,n,60,47,2883,20.3],
      [h,h,h,vh,n,n,n,h,n,n,n,n,l,vh,n,n,h,h,h,l,h,n,15,12,504,13.5],
      [h,h,h,vh,n,n,n,h,n,n,n,n,l,vh,vh,n,vh,n,h,vl,h,n,6.2,8,197,9.6],
      [h,h,h,vh,vl,n,l,vh,n,n,n,n,n,h,l,n,vh,n,n,vl,h,n,n,8,294,9.5],
      [h,h,h,vh,n,l,l,n,n,n,n,n,l,n,vh,n,vh,h,h,l,h,n,5.3,6,173,8.7],
      [h,h,h,vh,l,l,n,n,n,n,n,h,l,h,n,n,n,h,h,vl,h,n,45.5,45,2645,21.0],
      [h,h,h,vh,l,n,n,n,n,n,n,vh,l,h,n,n,n,h,h,vl,h,n,28.6,83,1416,18.9],
      [h,h,h,vh,vl,l,n,n,n,n,n,vh,l,n,n,n,n,h,h,vl,h,n,30.6,87,2444,20.5],
      [h,h,h,vh,l,l,n,n,n,n,n,h,l,n,n,n,n,h,h,vl,h,n,35,106,2198,20.1],
      [h,h,h,vh,l,l,n,n,n,n,n,h,l,n,h,n,n,h,h,vl,h,n,73,126,4188,25.1],
      [h,h,h,vh,vl,vl,l,vh,n,n,n,n,l,vh,vh,n,vh,l,l,vl,h,n,23,36,2161,15.6],
      [h,h,h,vh,vl,l,l,l,n,n,n,n,l,l,l,n,h,h,h,vl,h,n,464,1272,32002,53.4],
      [h,h,h,vh,n,n,n,l,n,n,n,n,n,vh,vh,n,n,l,n,l,h,n,91,156,2874,22.6],
      [h,h,h,vh,l,h,n,n,n,n,vh,vh,n,h,h,n,n,l,n,vl,h,n,24,176,1541,20.3],
      [h,h,h,vh,vl,l,n,n,n,n,n,n,n,l,vl,n,n,n,h,vl,h,n,10,122,1225,16.2],
      [h,h,h,vh,vl,l,l,l,n,n,n,h,h,n,n,n,n,l,l,vl,h,n,8.2,41,855,13.1],
      [h,h,h,vh,l,l,l,h,n,n,h,vh,vh,vh,vh,n,n,l,l,vl,h,l,5.3,14,533,9.3],
      [h,h,h,vh,n,n,l,n,n,n,n,h,h,n,n,n,vh,n,h,vl,h,n,4.4,20,216,10.6],
      [h,h,h,vh,vl,l,l,vl,n,n,n,n,l,h,l,n,vh,h,h,vl,h,n,6.3,18,309,9.6],
      [h,h,h,vh,vl,h,l,vh,n,n,vh,vh,n,h,n,n,h,l,l,vl,h,l,27,958,3203,21.1],
      [h,h,h,vh,vl,n,l,h,n,n,h,vh,vh,n,n,n,n,l,l,vl,h,vl,17,237,2622,16.0],
      [h,h,h,vh,n,vh,l,vh,n,n,xh,vh,n,vh,vh,n,vh,h,h,vl,h,n,25,130,813,20.9],
      [h,h,h,vh,n,n,l,h,n,n,n,h,n,n,n,n,n,n,n,vl,h,n,23,70,1294,18.2],
      [h,h,h,vh,vl,h,l,vh,n,n,h,h,n,h,h,n,l,l,l,vl,h,l,6.7,57,650,11.3],
      [h,h,h,vh,n,n,l,h,n,n,n,n,l,h,h,n,n,h,n,vl,h,n,28,50,997,16.4],
      [h,h,h,vh,n,l,l,vh,n,n,h,vh,h,n,vh,n,vh,vl,vl,vl,h,n,9.1,38,918,15.3],
      [h,h,h,vh,n,n,l,h,n,n,n,n,n,vh,h,n,vh,n,n,vl,h,n,10,15,418,11.6],
      ])



def sdiv(lst, tiny=3,cohen=0.3,
         num1=lambda x:x[0], num2=lambda x:x[1]):
  "Divide lst of (num1,num2) using variance of num2."
  #----------------------------------------------
  class Counts(): # Add/delete counts of numbers.
    def __init__(i,inits=[]):
      i.zero()
      for number in inits: i + number 
    def zero(i): i.n = i.mu = i.m2 = 0.0
    def sd(i)  : 
      if i.n < 2: return i.mu
      else:       
        return (max(0,i.m2)*1.0/(i.n - 1))**0.5
    def __add__(i,x):
      i.n  += 1
      delta = x - i.mu
      i.mu += delta/(1.0*i.n)
      i.m2 += delta*(x - i.mu)
    def __sub__(i,x):
      if i.n < 2: return i.zero()
      i.n  -= 1
      delta = x - i.mu
      i.mu -= delta/(1.0*i.n)
      i.m2 -= delta*(x - i.mu)    

  #----------------------------------------------
  def divide(this,small): #Find best divide of 'this'
    lhs,rhs = Counts(), Counts(num2(x) for x in this)
    n0, least, cut = 1.0*rhs.n, rhs.sd(), None
    for j,x  in enumerate(this): 
      if lhs.n > tiny and rhs.n > tiny: 
        maybe= lhs.n/n0*lhs.sd()+ rhs.n/n0*rhs.sd()
        if maybe < least :  
          if abs(lhs.mu - rhs.mu) >= small:
            cut,least = j,maybe
      rhs - num2(x)
      lhs + num2(x)    
    return cut,least
  #----------------------------------------------
  def recurse(this, small,cuts):
    cut,sd = divide(this,small)
    if cut: 
      recurse(this[:cut], small, cuts)
      recurse(this[cut:], small, cuts)
    else:   
      cuts += [(sd * len(this)/len(lst),this)]
    return cuts
  #---| main |-----------------------------------
  small = Counts(num2(x) for x in lst).sd()*cohen
  if lst: 
    return recurse(sorted(lst,key=num1),small,[])

def fss(d=coc81(),want=0.25):
  rank=[]
  for i in range(d.sfem):
    xs=sdiv(d.projects,
         num1=lambda x:x[i],
         num2=lambda x:x[d.effort])
    xpect = sum(map(lambda x: x[0],xs))
    rank += [(xpect,i)]
  rank = sorted(rank)
  keep = int(len(rank)*want)
  doomed= map(lambda x:x[1], rank[keep:])
  for project in d.projects:
    for col in doomed:
      project[col] = 3
  return d

def less(d=coc81(),n=2):
  skipped = 0
  names0 = d.names
  toUse,doomed = [],[]
  for v in Features.values():
    toUse += v[:n]
  for n,name in enumerate(names0):
    if n >= d.sfem:
      break
    if not has(name,toUse):
      doomed += [n]
  for project in d.projects:
    for col in doomed:
      project[col] = 3
  return d

def meanr(lst):
  total=n=0.00001
  for x in lst:
    if not x == None:
      total += x
      n += 1
  return total/n

def tothree(lst):
  below=lst[:2]
  above=lst[3:]
  m1 = meanr(below)
  m2=  meanr(above)
  below = [m1 for _ in below]
  above = [m2 for _ in above]
  return below + [lst[2]] + above

# splits vl, l, n, h, vh into below, n, above
def rr3(lst):
  #return lst 
  r = 1
  if lst[0]> 2 : r = 0
  def rr1(n): return round(x,r) if x else None
  tmp= tothree([rr1(x) for x in lst])
  return tmp

def rr5(lst):
  if lst[0] > 2:
    return [6,5,4,3,2,1]
  if lst[0] < 0:
    return [0.8, 0.9, 1, 1.1, 1.2, 1.3]
  return   [1.2,1.1,1,0.9,0.8,0.7]

def rrs5(d):
  for k in d: d[k] = rr5(d[k])
  return d

def rrs3(d):
  for k in d: d[k] = rr3(d[k])
  return d


def detune(m,tun=tunings()):
  def best(at,one,lst):
    least,x = 100000,None
    for n,item in enumerate(lst):
      if item:
        tmp = abs(one - item)
        if tmp < least:
          least = tmp
          x = n
    return x
  def detuned(project):
    for n,(name,val) in  enumerate(zip(m.names,project)):
      if n <= m.sfem:
        project[n] = best(n,val,tun[name]) + 1
    return project
  m.projects = [detuned(project) for 
                project in m.projects]
  for p in m.projects: print p
  return m


#########################################
# begin code

## imports
import random,math,sys
r    = random.random
any  = random.choice
seed = random.seed
exp  = lambda n: math.e**n
ln   = lambda n: math.log(n,math.e)
g    = lambda n: round(n,2)
def say(x):
  sys.stdout.write(str(x))
  sys.stdout.flush() 

def nl(): print ""
## classes
class Score(Thing):

  def run(self, want=None, **kw):
    if want is None:
      raise ValueError('want cannot be None')
    try:
      self.seen(self.estimator_func(**kw), want)
    except Exception, err:
      import traceback
      raise Exception("asdsa")


  def finalize(i) : 
    i.all = []
    i.residuals=[]
    i.raw=[]
    i.use=False
  def seen(i,got,want): 
    i.residuals += [abs(got - want)]
    i.raw += [got - want]
    tmp = i.mre(got,want)
    i.all += [tmp]
    return tmp
  def mar(i):
    return median(sorted(i.residuals))
    #return sum(i.residuals) / len(i.residuals)
  def sanity(i,baseline):  
    return i.mar()*1.0/baseline
  def mre(i,got,want): 
    return abs(got- want)*1.0/(0.001+want)
  def mmre(i): 
    return sum(i.all)*1.0/len(i.all)
  def medre(i): 
    return median(sorted(i.all))
  def pred(i,n=30):
    total = 0.0
    for val in i.all:
      if val <= n*0.01: total += 1
    return total*1.0/len(i.all) 

## low-level utils
def pretty(s):
  if isinstance(s,float):
    return '%.3f' % s
  else: return '%s' % s



def stats(l,ordered=False):
  if not ordered: l= sorted(l)
  p25= l[len(l)/4]
  p50= l[len(l)/2]  
  p75= l[len(l)*3/4]
  p100= l[-1]
  print p50, p75-p25, p100

## mode prep
def valued(d,opt,t=tunings()):
  for old in d.projects:
    for i,name in enumerate(d.names):
      if i <= d.sfem:
        tmp = old[i]
        if not isinstance(tmp,float):
          tmp  = old[i] - 1
          old[i] = round(t[name][tmp],opt.round)
  return d

####################################

def median(lst,ordered=False):
  if not ordered: lst= sorted(lst)
  n = len(lst)
  if n==0: return 0
  if n==1: return lst[0]
  if n==2: return (lst[0] + lst[1])*0.5
  if n % 2: return lst[n//2]
  n = n//2
  return (lst[n] + lst[n+1]) * 0.5

class Count:
  def __init__(i,name="counter"):
    i.name=name
    i.lo =    10**32
    i.hi= -1*10**32
    i._all = []
    i._also = None
  def keep(i,n):
    i._also= None
    if n > i.hi: i.hi = n
    if n < i.lo: i.lo = n
    i._all += [n]
  def centroid(i):return i.also().median
  def all(i): return i.also().all
  def also(i):
    if not i._also:
      i._all = sorted(i._all)
      if not i._all: 
        i._also = Thing(all=i._all,
                        median=0)
      else:
        i._also = Thing(all=i._all,
                      median=median(i._all))
    return i._also
  def norm(i,n):
    #return n
    return (n - i.lo)*1.0 / (i.hi - i.lo + 0.0001)

def clone(old,data=[]):
  return Model(map(lambda x: x.name,old.headers),
              data)

class Model:
  def __init__(i,names,data=[],indep=0):
    i.indep = indep
    i.headers = [Count(name) for name in names]
    i._also = None
    i.rows = []
    for row in data: i.keep(row)
  def centroid(i): return i.also().centroid
  def xy(i)      : return i.also().xy
  def also(i):
    if not i._also:
      xs, ys  = 0,0
      for row in i.rows:
        xs += row.x
        ys += row.y
      n = len(i.rows)+0.0001
      i._also=  Thing(
        centroid= map(lambda x: x.centroid(), 
                      i.headers),
        xy      = (xs/n, ys/n))
    return i._also
  def keep(i,row):
    i._also = None
    if isinstance(row,Row):
      content=row.cells
    else:
      content=row
      row = Row(cells=row)
    for cell,header in zip(content,i.headers):
      header.keep(cell)
    i.rows += [row]
   

class Row(Thing):
  def finalize(i):
    i.x = i.y = 0
  def xy(i,x,y):
    if not i.x:
      i.x, i.y = x,y 
  

def lo(m,x)     : return m.headers[x].lo
def hi(m,x)     : return m.headers[x].hi
def norm(m,x,n) : return m.headers[x].norm(n)

def cosineRule(z,m,c,west,east,slots):
  a = dist(m,z,west,slots)
  b = dist(m,z,east,slots)
  x= (a*a + c*c - b*b)/(2*c+0.00001) # cosine rule
  y= max(0,a**2 - x**2)**0.5
  return x,y

def fastmap(m,data,slots):
  "Divide data into two using distance to two distant items."
  one  = any(data)             # 1) pick anything
  west = furthest(m,one,data,slots)  # 2) west is as far as you can go from anything
  east = furthest(m,west,data,slots) # 3) east is as far as you can go from west
  c    = dist(m,west,east,slots)
  # now find everyone's distance
  lst = []
  for one in data:
    x,y= cosineRule(one,m,c,west,east,slots)
    one.xy(x,y)
    lst  += [(x, one)]
  lst = sorted(lst)
  wests,easts = [], []
  cut  = len(lst) // 2
  cutx = lst[cut][0]
  for x,one in  lst:
    what  = wests if x <= cutx else easts
    what += [one]
  return wests,west, easts,east,cutx,c

def dist(m,i,j,slots):
  "Euclidean distance 0 <= d <= 1 between decisions"
  d1,d2  = slots.what(i), slots.what(j)
  n      = len(d1)
  deltas = 0
  for d in range(n):
    n1 = norm(m, d, d1[d])
    n2 = norm(m, d, d2[d])
    inc = (n1-n2)**2
    deltas += inc
  return deltas**0.5 / n**0.5

def furthest(m,i,all,slots,
             init = 0,
             better = lambda x,y: x>y):
  "find which of all is furthest from 'i'"
  out,d= i,init
  for j in all:
    if not i == j:
      tmp = dist(m,i,j,slots)
      if better(tmp,d): out,d = j,tmp
  return out

def myCentroid(row,t):
  x1,y1=row.x,row.y
  out,d=None,10**32
  for leaf in leaves(t):
    x2,y2=leaf.m.xy()
    tmp = ((x2-x1)**2 + (y2-y1)**2)**0.5
    if tmp < d:
      out,d=leaf,tmp
  return out

def centroid2(row,t):
  x1,y1=row.x,row.y
  out=[]
  for leaf in leaves(t):
    x2,y2 = leaf.m.xy()
    tmp = ((x2-x1)**2 + (y2-y1)**2)**0.5
    out += [(tmp,leaf)]
  out = sorted(out)
  if len(out)==0:
    return [(None,None),(None,None)]
  if len(out) ==1:
    return out[0],out[0]
  else:
    return out[0],out[1]

    

def where0(**other):
  return Thing(minSize  = 10,    # min leaf size
               depthMin= 2,      # no pruning till this depth
               depthMax= 10,     # max tree depth
               b4      = '|.. ', # indent string
               verbose = False,  # show trace info?
               what    = lambda x: x.cells
   ).override(other)


def where(m,data,slots=None):
  slots = slots or where0()
  return where1(m,data,slots,0,10**32)

def where1(m, data, slots, lvl, sd0,parent=None):
  here = Thing(m=clone(m,data),
               up=parent,
               _west=None,_east=None,leafp=False)
  def tooDeep(): return lvl > slots.depthMax
  def tooFew() : return len(data) < slots.minSize
  def show(suffix): 
    if slots.verbose: 
      print slots.b4*lvl + str(len(data)) + suffix
  if tooDeep() or tooFew():
    show(".")
    here.leafp=True
  else:
    show("1")    
    wests,west, easts,east,cut,c = fastmap(m,data,slots)
    here.plus(c=c, cut=cut, west=west, east=east)
    sd1=Num("west",[slots.klass(w) for w in wests]).spread()
    sd2=Num("east",[slots.klass(e) for e in easts]).spread()
    goWest = goEast = True
    if lvl > 0:
      goWest = sd1 < sd0
      goEast = sd2 < sd0
    if  goWest:
      here._west = where1(m, wests, slots, lvl+1, sd1,here)
    if  goEast:
      here._east = where1(m, easts, slots, lvl+1, sd2,here)
  return here

def leaf(t,row,slots,lvl=1):
  if t.leafp: 
    return t
  else:
    x,_ = cosineRule(row, t.m, t.c,t.west,t.east,slots)
    return leaf(t._west if x <= t.cut else t._east,
                row,slots,lvl+1)

def preOrder(t):
  if t:
    yield t
    for kid in [t._west,t._east]:
      for out in preOrder(kid):
        yield out
      
def leaves(t):
  for t1 in preOrder(t):
    if t1.leafp:
      yield t1
          
def tprint(t,lvl=0):
  if t:
    print '|.. '*lvl + str(len(t.m.rows)), '#'+str(t._id)
    tprint(t._west,lvl+1)
    tprint(t._east,lvl+1)

import sys,math,random
sys.dont_write_bytecode = True

def go(f):
  "A decorator that runs code at load time."
  print "\n# ---|", f.__name__,"|-----------------"
  if f.__doc__: print "#", f.__doc__
  f()

# random stuff
seed = random.seed
any  = random.choice

# pretty-prints for list
def gs(lst) : return [g(x) for x in lst]
def g(x)    : return float('%.4f' % x) 
"""

### More interesting, low-level stuff

"""
def timing(f,repeats=10):
  "How long does 'f' take to run?"
  import time
  time1 = time.clock()
  for _ in range(repeats):
    f()
  return (time.clock() - time1)*1.0/repeats

def showd(d):
  "Pretty print a dictionary."
  def one(k,v):
    if isinstance(v,list):
      v = gs(v)
    if isinstance(v,float):
      return ":%s %g" % (k,v)
    return ":%s %s" % (k,v)
  return ' '.join([one(k,v) for k,v in
                    sorted(d.items())
                     if not "_" in k])




####################################

## high-level business knowledge
def effort(d,project, a=2.94,b=0.91):
  "Primitive estimation function"
  def sf(x) : return x[0].isupper()
  sfs , ems = 0.0, 1.0
  kloc = project[d.kloc]
  i = -1
  for name,val in zip(d.names,project):
    i += 1
    if i > d.sfem : break
    if sf(name):
      sfs += val 
    else:
      ems *=  val
  return a*kloc**(b + 0.01*sfs) * ems

def cart(train,test,most, **kwargs):
  from sklearn import tree
  indep = map(lambda x: x[:most+1], train)
  dep   = map(lambda x: x[most+1],  train)
  t = tree.DecisionTreeRegressor(**kwargs).fit(indep,dep)
  return t.predict(test[:most+1])[0]

def bayesian_ridge(train,test,most, **kwargs):
  from sklearn import linear_model
  indep = map(lambda x: x[:most+1], train)
  dep   = map(lambda x: x[most+1],  train)
  for k in ('opt', 'them', 'project', 'model', 'random_state'):
    try:
      del kwargs[k]
    except KeyError:
      pass
  t = linear_model.BayesianRidge(n_iter=1000, normalize=True, **kwargs).fit(indep,dep)
  # t = linear_model.BayesianRidge(**kwargs).fit(indep,dep)
  # return t.predict(test[:most+1])[0]
  return t.predict(test[:most+1])

verbose_names= ['Prec', 'Flex', 'Resl', 'Team', 'Pmat', 'rely', 'data', 'cplx', 'ruse',
     'docu', 'time', 'stor', 'pvol', 'acap', 'pcap', 'pcon', 'aexp', 'plex',  
     'ltex', 'tool', 'site', 'sced', 'kloc', 'effort', '?defects', '?months']
def verbose_cart(train,test,most, **kwargs):
  from sklearn.tree import DecisionTreeRegressor
  indep = map(lambda x: x[:most+1], train)
  dep   = map(lambda x: x[most+1],  train)
  t = DecisionTreeRegressor(**kwargs).fit(indep,dep)
  print '%', kwargs
  print zip(verbose_names, t.feature_importances_)
  return t.predict(test[:most+1])[0]

successful_fits = 0

def forest(train,test,most, **kwargs):
  # print "+ =============================================="
  # print len(train)
  # print len(test)
  # print most
  # print kwargs
  # print
  # print "- =============================================="
  # raise Exception("I know")
  global successful_fits
  from sklearn.ensemble import RandomForestRegressor
  indep = map(lambda x: x[:most+1], train)
  dep   = map(lambda x: x[most+1],  train)
  try:
    del kwargs['splitter']
  except KeyError:
    pass
  try:
    del kwargs['opt']
  except KeyError:
    pass
  #print kwargs
  try:
    rf = RandomForestRegressor(n_jobs=-1, **kwargs).fit(indep,dep)
  except:
    import traceback
    traceback.print_exc()
  # successful_fits += 1
  #print '%xxxxxxxxxxxxxxxxxxxxxx', 'fit', str(successful_fits)
  temp = rf.predict(test[:most+1])[0]
  #print ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> ",temp
  return temp

def get_forest(**kwargs):
  def forest_inner(train, test, most, **ignore):
    return forest(train, test, most, **kwargs)
  return forest_inner

def forest_with_trees(n_estimators):
  def forest_with_trees_inner(train, test, most, **kwargs):
    return forest(train, test, most, n_estimators=n_estimators)
  return forest_with_trees_inner

string_dealios = {'splitter': ('best', 'random')}
# ignoring max_depth, varying min_samples_leaf instead
# min_samples_leaf: stays at 1 for small datasets
# compute_importances: maybe later
int_dealios = {'min_samples_split': (1, 100),
               'max_leaf_nodes': (2, 100)}
# float_dealios = {'min_density': (0,1)}

def get_carts(splitter, min_samples_split, max_leaf_nodes):
  # using a wrapper instead of partial because the rig is gross and we need
  # to ignore uncaptured kwargs
  def partial_cart(train, test, most, **kw):
    return cart(train, test, most,
                splitter=splitter,
                min_samples_split=min_samples_split,
                max_leaf_nodes=max_leaf_nodes)
  return partial_cart


def get_rand_cart(string_dealios=string_dealios, int_dealios=int_dealios):
  '''
  some kinda magic up in here
  '''

  ivs = {}
  for k, v in string_dealios.iteritems():
    ivs[k] = IV(valid_inputs=v)
  for k, v in int_dealios.iteritems():
    ivs[k] = IV(lo=min(v), hi=max(v), gen_type=int)

  def rand_cart(train, test, most, **kw):
    return min([cart(train, test, most,
                **{k: v() for k, v in ivs.iteritems()}) for _ in range(1000)])

  return rand_cart


def get_knn_estimator(k):
  '''
  returns a closure that calculates knn for the given k
  '''
  @show_params
  def knn_estimator(model, them, project, opt, **kw):
    # ignore excess kwargs. Don't judge me
    return knn(model(), them, project, opt, k)
  knn_estimator.__name__ += '_{}'.format(str(k))
  return knn_estimator


def nc(n):
  return True #say(chr(ord('a') + n))
def loo(s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,
        s12,s13,s14,s15,s16,s17,s18,s19,s20,s21,s22,s23,s24,s25,s26,
        s27,s28,s29,s30,s31,s32,s33,s34,s35,s36,s37,s38,s39,s40,s41,
        s42,s43,s44,s45,s46,s47,s48,s49,
        score_list,
        model=nasa93,t=tunings(),opt=None,detuning=True, seed=1):
  "Leave one-out"
  if opt == None: opt=options()
  d= model(opt)
  for i,project in enumerate(d.projects):
    import sys
    sys.stderr.write(str(i)); sys.stderr.flush()
    want = project[d.effort]
    them = d.projects[:i] + d.projects[i+1:]
    for s in score_list:
      import time
      # print '% start:', time.time()
      # print '%', s
      try:
        #print "+++++++++++++++++++++++++ ",want,model,
        s.run(want=want, model=model, them=them, project=project, opt=opt,
              train=them, test=project, most=d.kloc, random_state=seed)
        # print '% end:', time.time()
      except AttributeError:
        raise Exception("Something wrong")
        pass

    # 
    if s15.use:
      nc(15)
      got15=knn(model(),them,project,opt,5); s15.seen(got15,want)

    if s16.use:
      nc(16)
      got16=knn(model(),them,project,opt,3); s16.seen(got16,want)
    if s17.use:
      nc(17)
      got17=knn(model(),them,project,opt,1); s17.seen(got17,want)
    #say(0)
    if s5.use or s7.use: 
      nc(5)
      got5,got7  = vasil(model,them,project); s5.seen(got5,want); s7.seen(got7,want)
    #say(1)
    if s1.use:
      nc(1)
      got1  = wildGuess(d,them,opt); s1.seen(got1,want)
    #say(2)
    if s4.use:
      nc(4)
      got4  = cart(them, project,d.kloc); s4.seen(got4,want)
    #say(5)
    if s8.use:
      nc(8)
      got8  = loc(d,them,project,3);     s8.seen(got8,want)
    if s18.use:
      nc(18)
      got18 = loc(d,them,project,1);     s18.seen(got18,want)
    #say(6)
    if s9.use or s10.use or s19.use or s20.use or s21.use or s22.use:
      project1 = project[:]
      project1[d.kloc]=0
      them1=[]
      for one in them: 
        tmp=one[:]
        tmp[d.kloc]=0
        them1 += [tmp]
      if s9.use or s10.use:
        nc(9)
        got9,got10  = vasil(model,them1,project1);
        s9.seen(got9,want); s10.seen(got10,want)
      if s19.use:
        nc(19)
        got19=knn(model(),them1,project1,opt,5); s19.seen(got19,want)
      if s20.use:
        nc(20)
        got20=knn(model(),them1,project1,opt,3); s20.seen(got20,want)
      if s21.use:
        nc(21)
        got21=knn(model(),them1,project1,opt,1); s21.seen(got21,want)
      if s22.use:
        nc(22)
        got22=cart(them1, project1,d.kloc);s22.seen(got22,want)

  if s2.use or s3.use:
    d= model(opt)
    d = valued(d,opt)
    for i,project in enumerate(d.projects):     
      want = project[d.effort]
      them = d.projects[:i] + d.projects[i+1:]
      if s2.use:
        nc(2)
        got2 = effort(d,project,2.94,0.91);   s2.seen(got2,want)
      if s3.use:
        nc(3)
        a,b  = coconut(d,them,opt);           
        got3 = effort(d,project,a,b);          s3.seen(got3,want)

  if s11.use or s12.use:
    #if not detuning: return True
    t=rrs3(tunings())
    d=model()
    d = valued(d,opt,t=t)
    for i,project in enumerate(d.projects):
      want= project[d.effort]
      them= d.projects[:i] + d.projects[i+1:]
    #say(7)
      if s11.use:
        nc(11)
        got11=effort(d,project,2.94,0.91); s11.seen(got11,want)
      if s12.use:
        nc(12)
        a,b=coconut(d,them,opt)
    #say(8)
        got12= effort(d,project,a,b); s12.seen(got12,want)
  if s23.use or s24.use or s25.use or s26.use:
     t = rrs3(tunings())
     d = model()
     d = valued(d,opt,t=t)
     for i,project in enumerate(d.projects):
       want= project[d.effort]
       them= d.projects[:i] + d.projects[i+1:]
       for n,s in [(8,s23), (12,s24), (16,s25),(4,s26)]:
         nc(23)
         them = shuffle(them)[:n]
         a,b = coconut(d,them,opt)
         got = effort(d,project,a,b); s.seen(got,want)
  if s27.use or s28.use or s29.use:
     for n,s in [(1,s27),(2,s28),(3,s29)]:
       t = rrs3(tunings())
       d = model()
       d = less(d,n)
       d = valued(d,opt,t=t)
       for i,project in enumerate(d.projects):
         nc(28)
         want= project[d.effort]
         them= d.projects[:i] + d.projects[i+1:]
         a,b = coconut(d,them,opt)
         got = effort(d,project,a,b); s.seen(got,want)
  if s30.use or s31.use or s32.use or s33.use or s34.use or s35.use or s36.use or s37.use or s38.use or s39.use or s40.use or s41.use:
     for n1,n2,s in [(0.25,4,s30),(0.25,8,s31),(0.25,12,s32),(0.25,16,s33),
                     (0.5, 4,s34),(0.5, 8,s35),(0.5, 12,s36),(0.5, 16,s37),
                     (1,4,s38),(1,8,s39),(1,12,s40),(1,16,s41)]:
       t = rrs3(tunings())
       d = model()
       d.projects = shuffle(d.projects)[:n2]
       d = fss(d,n1)
       d = valued(d,opt,t=t)
       for i,project in enumerate(d.projects):
         nc(36)
         want= project[d.effort]
         them= d.projects[:i] + d.projects[i+1:]
         a,b = coconut(d,them,opt)
         got = effort(d,project,a,b); s.seen(got,want)
    
  if  s13.use or s14.use:
    t=rrs5(tunings())
    d=model()
    d = valued(d,opt,t=t)
    for i,project in enumerate(d.projects):
      want= project[d.effort]
      them= d.projects[:i] + d.projects[i+1:]
    #say(9)
      if s13.use:
        nc(13)
        got13=effort(d,project,2.94,0.91); s13.seen(got13,want)
      if s14.use:
        nc(14)
        a,b=coconut(d,them,opt)
    #say("+")
        got14= effort(d,project,a,b); s14.seen(got14,want)

  if s42.use or s43.use or s44.use or s45.use or s46.use or s47.use or s48.use or s49.use:
     n1 = 0.5
     n2 = 8
     for noise,(carts,cocs,nuts,nears) in [
         (.25, (  s42, s44, s46, s48)),
         (.5, (  s43,  s45,s47, s49))
         ]:
       t = rrs3(tunings())
       d = model()
       d.projects = shuffle(d.projects)[:n2]
       d = fss(d,n1)
       d = valued(d,opt,t=t)
       for project in d.projects:
           old = project[d.kloc]
           new = old * ((1 - noise) + 2*noise*random.random())
           project[d.kloc]= new
       for i,project in enumerate(d.projects):
         nc(42)
         want= project[d.effort]
         them= d.projects[:i] + d.projects[i+1:]
         a,b=coconut(d,them,opt)
         nuts.seen(effort(d,project,a,b)      ,want)
         carts.seen(cart(them, project,d.kloc),want)
         cocs.seen(effort(d,project)          ,want)
        
         

def loc(d,them,project,n):
  me = project[d.kloc]
  all= sorted([(abs(me-x[d.kloc]),x[d.effort]) for x in them])
  one = two = three = four = five = all[0][1]
  if len(them) > 1: two = all[1][1]
  if len(them) > 2: three=all[2][1]
  if len(them) > 3: four=all[3][1]
  if len(them) > 4: five=all[4][1]
  # look at that: mean works as well as triangular kernel
  if n == 1 : return one
  if n == 2 : return (one *2 + two*1)/3
  if n == 3 : return  (one*3 + two*2+ three*1)/6
  if n == 4 : return (one * 4 + two * 3 + three * 2  + four * 1)/10
  return (one*5 + two*4 + three*3 + four*2 + five*1)/15
#  if n == 1 : return one
#  if n == 2 : return (one *1 + two*1)/2
#  if n == 3 : return  (one*1 + two*1+ three*1)/3
#  if n == 4 : return (one * 1 + two * 1 + three * 1  + four * 1)/4
#  return (one*1 + two*1 + three*1 + four*1 + five*1)/5

def walk(lst):
  lst = sorted([(median(x[1].all),x[0],x[1].all) for x in lst])
  say( lst[0][1])
  walk1(lst[0],lst[1:])
  print ""

def walk1(this,those):
  if those:
    that=those[0]
    _,n1=this[1], this[2]
    w2,n2=that[1], that[2]
    if mwu(n1,n2) :
      say(" < "+ str(w2))
      walk1(that,those[1:])
    else:
      say(" = " + str(w2))
      walk1(("","",n1+n2),those[1:])

def a12slow(lst1,lst2,rev=True):
  "how often is x in lst1 more than y in lst2?"
  more = same = 0.0
  for x in lst1:
    for y in lst2:
      if   x==y : same += 1
      elif rev     and x > y : more += 1
      elif not rev and x < y : more += 1
  x= (more + 0.5*same) / (len(lst1)*len(lst2))
  #if x > 0.71: return g(x),"B"
  #if x > 0.64: return g(x),"M"
  return x> 0.6 #g(x),"S"

def a12cmp(x,y):
  if y - x > 0 : return 1
  if y - x < 0 : return -1
  else: return 0

a12s=0
def a12(lst1,lst2, gt= a12cmp):
  "how often is x in lst1 more than y in lst2?"
  global a12s
  a12s += 1
  def loop(t,t1,t2): 
    while t1.j < t1.n and t2.j < t2.n:
      h1 = t1.l[t1.j]
      h2 = t2.l[t2.j]
      h3 = t2.l[t2.j+1] if t2.j+1 < t2.n else None 
      if gt(h1,h2) < 0:
        t1.j  += 1; t1.gt += t2.n - t2.j
      elif h1 == h2:
        if h3 and gt(h1,h3) < 0:
            t1.gt += t2.n - t2.j  - 1
        t1.j  += 1; t1.eq += 1; t2.eq += 1
      else:
        t2,t1  = t1,t2
    return t.gt*1.0, t.eq*1.0
  #--------------------------
  lst1 = sorted(lst1, cmp=gt)
  lst2 = sorted(lst2, cmp=gt)
  n1   = len(lst1)
  n2   = len(lst2)
  t1   = Thing(l=lst1,j=0,eq=0,gt=0,n=n1)
  t2   = Thing(l=lst2,j=0,eq=0,gt=0,n=n2)
  gt,eq= loop(t1, t1, t2)
  #print gt,eq,n1,n2
  return gt/(n1*n2) + eq/2/(n1*n2)


class Counts(): # Add/delete counts of numbers.
  def __init__(i,inits=[]):
    i.n = i.mu = i.m2 = 0.0
    for number in inits: i + number 
  def sd(i) : 
    if i.n < 2: return i.mu
    else:       
      return (i.m2*1.0/(i.n - 1))**0.5
  def __add__(i,x):
    i.n  += 1
    delta = x - i.mu
    i.mu += delta/(1.0*i.n)
    i.m2 += delta*(x - i.mu)
  
def wildGuess(d,projects,opt):
  tally = 0
  for _ in xrange(opt.guesses):
    project = any(projects)
    tally += project[d.effort]
  return tally*1.0/opt.guesses

def run_de_cart(train, test, most, **kw):
  s = DifferentialEvolution(partial(CARTModel, train, test, most))
  return s.run().best

def run_pso_cart(train, test, most, **kw):
  s = ParticleSwarmOptimizer(partial(CARTModel, train, test, most))
  return s.run().best

def run_de_forest(train, test, most, **kw):
  s = DifferentialEvolution(partial(RFModel, train, test, most))
  return s.run().best

def run_pso_forest(train, test, most, **kw):
  s = ParticleSwarmOptimizer(partial(RFModel, train, test, most))
  return s.run().best

def get_de_verbose_cart(n):
  def run_de_verbose_cart(train, test, most, **kw):
    s = DifferentialEvolution(partial(VerboseCARTModel, n, train, test, most))
    return s.run().best
  return run_de_verbose_cart

def coconut(d,tests,opt,lvl=None,err=10**6,
            a=10,b=1,ar=10,br=0.5):
  "Chase good  a,b settings"
  #return 2.94,0.91
  def efforts(a,b):
    s=Score()
    for project in tests:
      got = effort(d,project,a,b)
      want = project[d.effort]
      s.seen(got,want)
    return s.mmre()
  if lvl == None: lvl=opt.levels
  if lvl < 1 : return a,b
  old = err
  for _ in range(opt.samples):
    a1 = a - ar + 2*ar*r()
    b1 = b - br + 2*br*r()
    tmp = efforts(a1,b1)
    if tmp < err:
      a,b,err = a1,b1,tmp
  if (old - err)/old < opt.epsilon:
    return a,b
  else:
    return coconut(d,tests,opt,lvl-1,err, a=a,b=b,
                   ar=ar*opt.shrink,
                   br=br*opt.shrink)

## sampple main
def main(model=nasa93):
  xseed(1)
  for shrink in [0.66,0.5,0.33]:
    for sam in [5,10,20]:
      for lvl in [5,10,20]:
        for rnd in [0,1,2]:
          opt=options()
          opt.shrink=shrink
          opt.samples=sam
          opt.round = rnd
          opt.levels = lvl
          loo(model=model,opt=opt)


#########################################
# start up code


def mwu(l1,l2):
  import numpy as np
  from scipy.stats import  mannwhitneyu
  #print "l1>",map(g,sorted(l1))
  #print "l2>",map(g,sorted(l2))
  _, p_value =  mannwhitneyu(np.array(l1), 
                             np.array(l2))
  return p_value <= 0.05

# for e in [1,2,4]:
#   print "\n"
#   l1 = [r()**e for _ in xrange(100)]
#   for y in [1.01,1.1,1.2,1.3,1.4, 1.5]:
#     l2 = map(lambda x: x*y,l1)
#     print e,y,mwu(l1,l2)

def test1(lst,repeats=10,models=[coc81],what='locOrNot'):
  #seed(1)
  #print repeats,what,map(lambda x:x.__name__,models)
#for m in [ newCIIdata, xyz14,nasa93,coc81]:
  import time
  detune=False
  for m  in models:  
      print ">>>>>>>>>>>>>>>>>>>",m
     #(newCIIdataDeTune,True),#, #, 
#     (xyz14deTune,True)
 #    #(coc81,True),
     #(nasa93,True)
  #  ]:
      s1=Score();  s2=Score(); s3=Score(); s4=Score();
      s5=Score();  s6=Score(); s7=Score(); s8=Score()
      s9=Score();  s10=Score(); s11=Score(); s12=Score();
      s13=Score(); s14=Score();
      s15=Score();  s16=Score(); s17=Score(); s18=Score()
      s19=Score();  s20=Score(); s21=Score();
      s22=Score()
      s23=Score()
      s24=Score(); s25=Score(); s26=Score()
      s27=Score(); s28=Score(); s29=Score()
      s30=Score(); s31=Score(); s32=Score()
      s33=Score(); s34=Score(); s35=Score()
      s36=Score(); s37=Score(); s38=Score()
      s39=Score(); s40=Score(); s41=Score()

      s42=Score(); s43=Score(); s44=Score()
      s45=Score(); s46=Score(); s47=Score()
      s48=Score(); s49=Score();
      # loc or no loc
      # exps =dict(locOrNot = [("coc2000",s2),("coconut",s3),
      #                        ("loc(3)",s8), ("loc(1)",s18), 
      #                        #('knear(3)',s16),  ("knear(3) noloc",s20),
      #                        #('knear(1)',s17),("knear(1) noloc",s21) 
      #                        ],
      #            basicRun = [("coc2000",s2),("coconut",s3),
      #                        ('knear(3)',s16),('knear(1)',s17),
      #                        #("cluster(1)",s5),
      #                        ("cluster(2)",s7),   
      #                        ("cart",s4)],
      #            qualitative= [("coc2000",s2),("coconut",s3),
      #                          #('knear(3)',s16),('knear(1)',s17),
      #                          ("coco2000(simp)",s13), ("coconut(simp)",s14),
      #                          ("coco2000(lmh)",s11), ("coconut(lmh)",s12)],
      #            other    =  [('(c=1)n-noloc',s9),('(c=2)n-noloc',s10)],
      #            less     = [("coc2000",s2),("coconut",s3),
      #                        ("coco2000(lmh)",s11), ("coconut(lmh)",s12),
      #                        ('coconut(lmh8)',s23),('coconut(lmh12)',s24), 
      #                        ('coconut(lmh16)',s25),
      #                        ('coconut(lmh4)',s26)],
      #            lessCols = [("coc2000",s2),("coconut",s3),
      #                        ('coconut(just5)',s27),
      #                        ('coconut(just10)',s28),
      #                        ('coconut(just15)',s29)],
      #            fssCols = [("coc2000",s2),("coconut",s3),
      #                       ('coconut:c*0.25,r=4',s30),
      #                       ('coconut:c*0.25,r=8',s31),
      #                       #('coconut:c*0.25,r=12',s32),
      #                       #('coconut:c*0.25,r=16',s33),
      #                       ('coconut:c*0.5,r=4',s34),
      #                       ('coconut:c*0.5,r=8',s35),
      #                       #('coconut:c*0.5,r=12',s36),
      #                       #('coconut:c*1,r=16',s37),
      #                       ('coconut:c*1,r=4',s38),
      #                       ('coconut:c*1,r=8',s39),
      #                       #('coconut:c*1,r=12',s40),
      #                       #('coconut:c*1,r=16',s41)
      #                     ],
      #             noise = [  ("cart",s4),               ("cart/4",s42),               ("cart/2",s43),         
      #                        ("coc2000",s2),            ("coc2000n/4",s44),           ("coc2000n/2",s45),
      #                        ('coconut:c*0.5,r=8',s35), ('coconut:c*0.5r=8n/4',s46) , ('coconut:c*0.5,r=8n/2',s47),
      #                        ('knear(1)',s17),          ('knear(1)/4',s48),           ('knear(1)/2',s49)
      #                      ],
      #             knnOnly = [
      #               ('knear(3)',s16),('knear(1)',s17),
      #             ],
      #             knnOnlyNew = [
      #                       ('knear({})'.format(n+1), Score(estimator_func=get_knn_estimator(n+1)))
      #                        for n in range(10)
      #                      ],
      #             cartRand = [
      #               ('cart_rand', Score(estimator_func=get_rand_cart()))
      #             ],
      #             cartComponents = [
      #               ('cartcomponents',
      #                Score(estimator_func=get_de_verbose_cart(len(m().projects) - 1)))
      #             ],
      #             allTheCart = [
      #               ('cart({0}, {1}, {2})'.format(splitter,
      #                                             min_samples_split,
      #                                             max_leaf_nodes),
      #                Score(estimator_func=get_carts(splitter,
      #                                               min_samples_split,
      #                                               max_leaf_nodes)))
      #                for splitter, min_samples_split, max_leaf_nodes in
      #                    product(('best', 'random'),
      #                            (2**n for n in range(0, 10)),
      #                            (2**n for n in range(0, 10)))
      #             ],
      #             search = [
      #               ('de(cart)', Score(estimator_func=run_de_cart)),
      #               # ('de(rf)', Score(estimator_func=run_de_forest)),
      #               ("coc2000",s2),("coconut",s3),
      #               ('knear(3)',s16),('knear(1)',s17),
      #               ("cart",s4)
      #             ],
      #             forestOnly = [
      #               ('forest({} trees)'.format(n),
      #                Score(estimator_func=forest_with_trees(n)))
      #                for n in (150,)
      #             ] + [('de(cart)', Score(estimator_func=run_de_cart)),
      #                  ('de(rf)', Score(estimator_func=run_de_forest))],
      #             deKNN = [
      #               ('de(knn)', Score(estimator_func=run_de_knn))
      #             ],
      #             bayesianRidge = [
      #               ('ridge', Score(estimator_func=bayesian_ridge))
      #             ],
      #             dePsoCart = [
      #               ('de(cart)', Score(estimator_func=run_de_cart)),
      #               ('pso(cart)', Score(estimator_func=run_pso_cart)),
      #             ],
      #             forestTuned = [
      #               ('forest(mss={},msl={})'.format(x, y),
      #                Score(estimator_func=get_forest(min_samples_split=x, min_samples_leaf=y, n_estimators=100, max_features="sqrt")))
      #                for x, y in product((2**n for n in range(5)), (2**n for n in range(5)))
      #             ],
      #             shootout = [
      #               # ('de(cart)', Score(estimator_func=run_de_cart)),
      #               # # ('de(rf)', Score(estimator_func=run_de_forest)),
      #               # ("coc2000",s2),("coconut",s3),
      #               # ('knear(3)',s16),('knear(1)',s17),
      #               # ("cart",s4),
      #               ('forest(mss=1,msl=2)',
      #                Score(estimator_func=get_forest(min_samples_split=1,
      #                                                min_samples_leaf=2,
      #                                                n_estimators=150))),
      #               ('forest(mss=2,msl=1)',
      #                Score(estimator_func=get_forest(min_samples_split=2,
      #                                                min_samples_leaf=1,
      #                                                n_estimators=150)))
      #             ]
      #            )
      # lst = exps[what]
      # for x in lst:
      #   print x
      #   print
      # raise Exception("I am here")
      print '%',what
      for _,s in lst: s.use=True
      t1=time.clock()
      import sys
      
      #say("%")
      # print "Repeat: >>>>>>>>>>>>>>>>>>>>>>> ",repeats
      for i in range(repeats):
        sys.stderr.write(str(i)); sys.stderr.flush()
        say(' ' + str(i))
        loo(s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12,s13,
            s14,s15,s16,s17,s18,s19,s20,s21,s22,s23,s24,s25,s26,
             s27,s28,s29,s30,s31,s32,
            s33,s34,s35,s36,s37,s38,s39,s40,s41,s42,s43,s44,s45,s46,s47,s48,s49,
            score_list=tuple(x[1] for x in lst),
            # score_list=[],
            model=m,detuning=detune, seed=i)
      # global bs
      # global a12s
      # bs = a12=0
      # t2 = time.clock()
      # print "="
      # # for x in lst:
      # #   print x[1]

      assert(len(lst) == 1 ),"wrong1"
      return lst[0][1].all
      # print "Score>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>> : ",lst
      # rdivDemo([[x[0]] + x[1].all for x in lst if x[1].all])
      # t3 = time.clock()
      # print "\n :learn",t2-t1,":analyze",t3-t2,":boots",bs,"effects",a12s,":conf",0.99**bs
      
#print 'B>', bootstrap([1,2,3,4,5],[1,2,3,4,5])

@show_params
def knn(src,them,project,opt,k):
  slots = where0(what= lambda x:cocVals(x,src.effort))
  m0=Model(src.names,src.projects)
  m1=clone(m0,them)
  w = [None]*k
  ws = 0
  for i in range(k): ws += i+1
  for i in range(k): w[i] = (i+1)/ws
  w.reverse()
  #w = [1/k]*k
  
  dists =[(dist(m1,Row(cells=that),Row(cells=project),slots),that[src.effort])
          for that in them]
  est = 0
  for w1,(_,x) in zip(w,sorted(dists)[:k]):
    est += w1*x
  return est

def cocVals(row,n):
  if isinstance(row,Row):
    row=row.cells
  return row[:n]

def vasil(src,data,project):
  all = src()
  m0 = Model(all.names,all.projects)
  m1 = clone(m0,data)
  e  = all.effort
  slots = where0(what= lambda x:cocVals(x,e)
                 ,klass=lambda x:x.cells[all.effort])
  t     = where(m1,m1.rows,slots)
  row = Row(cells=project)
  got1 = got2 = Num(slots.klass(r) for r in data).median()
  (d1,c1),(d2,c2) = centroid2(row,t)
  if c1 or c2:
    w1,w2 = 1/(d1+0.0001), 1/(d2+0.0001)
    e1 = c1.m.centroid()[e]
    e2 = c2.m.centroid()[e]
    got2 = (w1*e1 + w2*e2) / (w1+w2)
    got1=myCentroid(row,t).m.centroid()[e]
  #got1b=leaf(t,row,slots).m.centroid()[e]
  return got1,got2

class Num:
  "An Accumulator for numbers"
  def __init__(i,name,inits=[]): 
    i.n = i.m2 = i.mu = 0.0
    i.all=[]
    i._median=None
    i.name = name
    i.rank = 0
    for x in inits: i.add(x)
  def s(i)       : return (i.m2/(i.n - 1))**0.5
  def add(i,x):
    i._median=None
    i.n   += 1   
    i.all += [x]
    delta  = x - i.mu
    i.mu  += delta*1.0/i.n
    i.m2  += delta*(x - i.mu)
  def __add__(i,j):
    return Num(i.name + j.name,i.all + j.all)
  def quartiles(i):
    def p(x) : return int(100*g(xs[x]))
    i.median()
    xs = i.all
    n  = int(len(xs)*0.25)
    return p(n) , p(2*n) , p(3*n)
  def median(i):
    if not i._median:
      i.all = sorted(i.all)
      i._median=median(i.all)
    return i._median
  def __lt__(i,j):
    return i.median() < j.median() 
  def spread(i):
    i.all=sorted(i.all)
    n1=i.n*0.25
    n2=i.n*0.75
    if len(i.all) <= 1:
      return 0
    if len(i.all) == 2:
      return i.all[1] - i.all[0]
    else:
      return i.all[int(n2)] - i.all[int(n1)]


def different(l1,l2):
  #return bootstrap(l1,l2) and a12(l2,l1)
  return a12(l2,l1) and bootstrap(l1,l2)


def scottknott(data,cohen=0.3,small=3, useA12=False,epsilon=0.01):
  """Recursively split data, maximizing delta of
  the expected value of the mean before and 
  after the splits. 
  Reject splits with under 3 items"""
  #data = [d for d in data if d.spread() < 0.75]
  all  = reduce(lambda x,y:x+y,data)
  #print sorted(all.all)
  same = lambda l,r: abs(l.median() - r.median()) <= all.s()*cohen
  if useA12: 
    same = lambda l, r:   not different(l.all,r.all) 
  big  = lambda    n: n > small    
  return rdiv(data,all,minMu,big,same,epsilon)

def rdiv(data,  # a list of class Nums
         all,   # all the data combined into one num
         div,   # function: find the best split
         big,   # function: rejects small splits
         same, # function: rejects similar splits
         epsilon): # small enough to split two parts
  """Looks for ways to split sorted data, 
  Recurses into each split. Assigns a 'rank' number
  to all the leaf splits found in this way. 
  """
  def recurse(parts,all,rank=0):
    "Split, then recurse on each part."
    cut,left,right = maybeIgnore(div(parts,all,big,epsilon),
                                 same,parts)
    if cut: 
      # if cut, rank "right" higher than "left"
      rank = recurse(parts[:cut],left,rank) + 1
      rank = recurse(parts[cut:],right,rank)
    else: 
      # if no cut, then all get same rank
      for part in parts: 
        part.rank = rank
    return rank
  recurse(sorted(data),all)
  return data

def maybeIgnore((cut,left,right), same,parts):
  if cut:
    if same(sum(parts[:cut],Num('upto')),
            sum(parts[cut:],Num('above'))):    
      cut = left = right = None
  return cut,left,right

def minMu(parts,all,big,epsilon):
  """Find a cut in the parts that maximizes
  the expected value of the difference in
  the mean before and after the cut.
  Reject splits that are insignificantly
  different or that generate very small subsets.
  """
  cut,left,right = None,None,None
  before, mu     =  0, all.mu
  for i,l,r in leftRight(parts,epsilon):
    if big(l.n) and big(r.n):
      n   = all.n * 1.0
      now = l.n/n*(mu- l.mu)**2 + r.n/n*(mu- r.mu)**2  
      if now > before:
        before,cut,left,right = now,i,l,r
  return cut,left,right

def leftRight(parts,epsilon=0.01):
  """Iterator. For all items in 'parts',
  return everything to the left and everything
  from here to the end. For reasons of
  efficiency, take a first pass over the data
  to pre-compute and cache right-hand-sides
  """
  rights = {}
  n = j = len(parts) - 1
  while j > 0:
    rights[j] = parts[j]
    if j < n: rights[j] += rights[j+1]
    j -=1
  left = parts[0]
  for i,one in enumerate(parts):
    if i> 0: 
      if parts[i]._median - parts[i-1]._median > epsilon:
        yield i,left,rights[i]
      left += one

bs=0
def bootstrap(y0,z0,conf=0.01,b=1000):
  """The bootstrap hypothesis test from
     p220 to 223 of Efron's book 'An
    introduction to the boostrap."""
  global bs
  bs += 1
  class total():
    "quick and dirty data collector"
    def __init__(i,some=[]):
      i.sum = i.n = i.mu = 0 ; i.all=[]
      for one in some: i.put(one)
    def put(i,x):
      i.all.append(x);
      i.sum +=x; i.n += 1; i.mu = float(i.sum)/i.n
    def __add__(i1,i2): return total(i1.all + i2.all)
  def testStatistic(y,z): 
    """Checks if two means are different, tempered
     by the sample size of 'y' and 'z'"""
    tmp1 = tmp2 = 0
    for y1 in y.all: tmp1 += (y1 - y.mu)**2 
    for z1 in z.all: tmp2 += (z1 - z.mu)**2
    s1    = (float(tmp1)/(y.n - 1))**0.5
    s2    = (float(tmp2)/(z.n - 1))**0.5
    delta = z.mu - y.mu
    if s1+s2:
      delta =  delta/((s1/y.n + s2/z.n)**0.5)
    return delta
  def one(lst): return lst[ int(any(len(lst))) ]
  def any(n)  : return random.uniform(0,n)
  y, z   = total(y0), total(z0)
  x      = y + z
  tobs   = testStatistic(y,z)
  yhat   = [y1 - y.mu + x.mu for y1 in y.all]
  zhat   = [z1 - z.mu + x.mu for z1 in z.all]
  bigger = 0.0
  for i in range(b):
    if testStatistic(total([one(yhat) for _ in yhat]),
                     total([one(zhat) for _ in zhat])) > tobs:
      bigger += 1
  return bigger / b < conf

def bootstrapd(): 
  def worker(n=30,mu1=10,sigma1=1,mu2=10.2,sigma2=1):
    def g(mu,sigma) : return random.gauss(mu,sigma)
    x = [g(mu1,sigma1) for i in range(n)]
    y = [g(mu2,sigma2) for i in range(n)]
    return n,mu1,sigma1,mu2,sigma2,\
        'different' if bootstrap(x,y) else 'same'
  print worker(30, 10.1, 1, 10.2, 1)
  print worker(30, 10.1, 1, 10.8, 1)
  print worker(30, 10.1, 10, 10.8, 1)
 

def rdivDemo(data,max=100):
  def z(x):
    return int(100 * (x - lo) / (hi - lo + 0.00001))
  data = map(lambda lst:Num(lst[0],lst[1:]),
             data)
  print ""
  ranks=[]
  for x in scottknott(data,useA12=True):
    ranks += [(x.rank,x.median(),x)]
  all=[]
  for _,__,x in sorted(ranks):
    all += x.quartiles()
  all = sorted(all)
  lo, hi = all[0], all[-1]
  print "{\\scriptsize \\begin{tabular}{l@{~~~}l@{~~~}r@{~~~}r@{~~~}c}"
  print "\\arrayrulecolor{darkgray}"
  print '\\rowcolor[gray]{.9}  rank & treatment & median & IQR & \\\\' #min= %s, max= %s\\\\' % (int(lo),int(hi))
  last = None
  for _,__,x in sorted(ranks):
    q1,q2,q3 = x.quartiles()
    pre =""
    if not last == None and not last == x.rank:
      pre= "\\hline"
    print pre,'%2s & %12s &    %s  &  %s & \quart{%s}{%s}{%s}{%s} \\\\' % \
        (x.rank+1, x.name, q2, q3 - q1, z(q1), z(q3) - z(q1), z(q2),z(100))
    last = x.rank 
  print "\\end{tabular}}"

def rdiv0():
  rdivDemo([
        ["x1",0.34, 0.49, 0.51, 0.6],
        ["x2",6,  7,  8,  9] ])

def rdiv1():
  rdivDemo([
        ["x1",0.1,  0.2,  0.3,  0.4],
        ["x2",0.1,  0.2,  0.3,  0.4],
        ["x3",6,  7,  8,  9] ])

def rdiv2():
  rdivDemo([
        ["x1",0.34, 0.49, 0.51, 0.6],
        ["x2",0.6,  0.7,  0.8,  0.9],
        ["x3",0.15, 0.25, 0.4,  0.35],
        ["x4",0.6,  0.7,  0.8,  0.9],
        ["x5",0.1,  0.2,  0.3,  0.4] ])

def rdiv3():
  rdivDemo([
      ["x1",101, 100, 99,   101,  99.5],
      ["x2",101, 100, 99,   101, 100],
      ["x3",101, 100, 99.5, 101,  99],
      ["x4",101, 100, 99,   101, 100] ])

def rdiv4():
  rdivDemo([
      ["1",11,12,13],
      ["2",14,31,22],
      ["3",23,24,31],
      ["5",32,33,34]])

def rdiv5():
  rdivDemo([
      ["1",11,11,11],
      ["2",11,11,11],
      ["3",11,11,11]])

def rdiv6():
  rdivDemo([
      ["1",11,11,11],
      ["2",11,11,11],
      ["4",32,33,34,35]])

#rdiv0(); rdiv1(); rdiv2(); rdiv3(); rdiv4(); rdiv5(); rdiv6()
#exit() 

def random_forest(repeat,exp,models,lst):
  repeats=10
  exp='locOrNot'
  models=[  'coc81',
            'nasa93']
  if len(sys.argv)>=2:
    repeats=eval(sys.argv[1])
  if len(sys.argv)>=3:
    exp=sys.argv[2]
  if len(sys.argv)>3:
    models=sys.argv[3:]

  print('''\documentclass{article}

  \usepackage{colortbl} % not sure if needed
  \usepackage[table]{xcolor} % not sure if needed

  %%%% needed %%%
  \usepackage{picture}
  \newcommand{\quart}[4]{\begin{picture}(100,6)%1
  {\color{black}\put(#3,3){\circle*{4}}\put(#1,3){\line(1,0){#2}}}\end{picture}}

  \begin{document}

  ''')

  test1(lst,repeats=repeats,models=map(eval,models),what=exp)

  print('''
  \end{document}
  ''')

class RandomForest(ModelBasic):
  def __init__(self,minR=-4,maxR=4,n=4,objf=1):
    self.minR=[2,2,100, 1]
    self.maxR=[32,32,1000, 16]
    self.n=n
    self.minVal=10000000
    self.maxVal=-1e6
    self.objf=objf
    self.past = [Log() for count in xrange(objf)]
    self.present = [Log() for count in xrange(objf)]
    self.lives=myModeloptions['Lives']
    self.functionDict = {}
    self.functionDict["f1"]="f1"


  def f1(self,listpoint,num=0):
    # convert = {de
    #            1 : 'auto',f chindea
    #            2 : 'sqrt',
    #            3 : 'log2'
    #           }
    repeats=1
    exp='locOrNot'
    models=['china']
    assert(len(listpoint) == 4),"Wrong!"
    print listpoint
    msl = int(listpoint[1])
    y = int(listpoint[2])
    z = int(round(listpoint[3]))


    mss = int(listpoint[0])
    
    lst = [
                    ('forest(mss={},msl={},ne={},mf={})'.format(mss,msl,y,z),
                     Score(estimator_func=get_forest(min_samples_split=mss, min_samples_leaf=msl, 
                      n_estimators=y, max_features=z)))
                     
                  ]


    print "\n +==============================================="
    print lst
    retlst = test1(lst,repeats=1,models=map(eval,models),what=exp)
    print retlst
    print len(retlst)
    print int(len(retlst)/4 * 3)
    print int(len(retlst)/4)
    print "\nMedian: ", median(retlst)," IQR: ", (retlst[int(len(retlst)/4 * 3)] - retlst[int(len(retlst)/4)])
 
    print "- ===================================="
    #raise Exception("I am here")
    return median(retlst)#,retlst[len(retlst)/4] - retlst[len(retlst)*3/4]
 
  def info(self):
    return "Fonseca~"

  def baseline(self,minR,maxR):
    emin = 1e6
    emax = -1e6
    for x in range(0,90000):
      solution = [(self.minR[z] + random.random()*(self.maxR[z]-self.minR[z])) for z in range(0,self.n)]
      result=0
      for i in xrange(self.objf):
        temp="f"+str(i+1)
        callName = self.functionDict[temp]
        result+=float(getattr(self, callName)(solution,i+1))
      #self.returnMax(result)
      #self.returnMin(result)
      emin = emin if emin < result else result
      emax = emax if emax > result else result
    return emin,emax

